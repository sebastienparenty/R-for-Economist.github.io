[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R for Economist",
    "section": "",
    "text": "Welcome\nThis course has been specifically designed for Master 1 students at the Toulouse School of Economics. Its aim is to teach the basics of R and data science culture, in an interactive and fun environment. 10 lessons of 1h30 each will introduce you to the world of R programming and all its possibilities.\n\n\n\n\n\nContact\nsebastien.parenty@tse-fr.eu\nhttps://www.tse-fr.eu/fr/people/sebastien-parenty"
  },
  {
    "objectID": "intro.html#r-who-are-you",
    "href": "intro.html#r-who-are-you",
    "title": "1  Introduction",
    "section": "1.1 R, who are you?",
    "text": "1.1 R, who are you?\nAccording to its wikipedia page:\n“R is a programming language for statistical computing and graphics supported by the R Core Team and the R Foundation for Statistical Computing. Created by statisticians Ross Ihaka and Robert Gentleman, R is used among data miners, bioinformaticians and statisticians for data analysis and developing statistical software. The core R language is augmented by a large number of extension packages containing reusable code and documentation.”\n\nImport and check DataSummaryPlotLinear modelPredictions\n\n\n\n\n\n\n\nyear\nGDP\nImport\nConsumption\nInvestment\nExport\n\n\n\n\n1950\n293.367\n15.501\n236.822\n50.810\n18.107\n\n\n1951\n310.358\n18.428\n253.291\n55.680\n20.277\n\n\n1952\n320.022\n18.967\n265.817\n56.183\n19.624\n\n\n1953\n331.083\n18.963\n277.979\n58.772\n19.373\n\n\n1954\n349.552\n19.754\n286.413\n64.056\n20.979\n\n\n1955\n368.120\n21.061\n300.344\n70.856\n21.944\n\n\n1956\n386.481\n25.039\n321.230\n76.320\n21.601\n\n\n1957\n407.802\n27.200\n335.088\n83.797\n23.460\n\n\n1958\n418.795\n26.057\n335.104\n87.987\n23.943\n\n\n1959\n429.983\n26.127\n342.147\n92.001\n26.912\n\n\n\n\n\n\n\n\n\n      year           GDP             Import        Consumption    \n Min.   :1950   Min.   : 293.4   Min.   : 15.50   Min.   : 236.8  \n 1st Qu.:1968   1st Qu.: 714.0   1st Qu.: 62.72   1st Qu.: 543.7  \n Median :1986   Median :1283.1   Median :182.44   Median :1027.6  \n Mean   :1986   Mean   :1317.4   Mean   :284.27   Mean   :1026.1  \n 3rd Qu.:2004   3rd Qu.:1950.2   3rd Qu.:489.71   3rd Qu.:1491.0  \n Max.   :2022   Max.   :2351.2   Max.   :828.61   Max.   :1837.7  \n   Investment         Export      \n Min.   : 50.81   Min.   : 18.11  \n 1st Qu.:180.73   1st Qu.: 55.71  \n Median :269.77   Median :178.82  \n Mean   :297.69   Mean   :277.40  \n 3rd Qu.:438.56   3rd Qu.:501.56  \n Max.   :575.35   Max.   :753.13  \n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel &lt;- lm(GDP ~ year, data = PIB)\nsummary(model)\n\n\nCall:\nlm(formula = GDP ~ year, data = PIB)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-208.19  -32.28   -0.80   29.75  116.39 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -59833.54     576.05  -103.9   &lt;2e-16 ***\nyear            30.79       0.29   106.2   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 52.22 on 71 degrees of freedom\nMultiple R-squared:  0.9937,    Adjusted R-squared:  0.9937 \nF-statistic: 1.127e+04 on 1 and 71 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\npredictions &lt;- predict(model, newdata = data.frame(year = 2023:2030))\npredictions\n\n       1        2        3        4        5        6        7        8 \n2456.703 2487.494 2518.286 2549.077 2579.868 2610.659 2641.450 2672.241 \n\n\n\n\n\n\n\n\n Download data as csv\n\n\n\n\n1.1.1 R studio\nRStudio is an integrated development environment (IDE) for the R programming language. It provides a graphical user interface (GUI) for writing, editing, and running R code. It also includes a number of features that make it easier to work with data, such as a code editor, a debugger, and a console. RStudio is a popular IDE for R, and it is used by a wide range of users, from students to researchers to data scientists.\nHere are some of the key features of RStudio:\n\nA code editor with syntax highlighting and auto-completion\nA debugger that allows you to step through your code line-by-line\nA console where you can run R commands\nA variety of tools for working with data, such as a data viewer and a data frame editor\nA built-in help system\n\nRStudio is a powerful tool that can help you be more productive when working with R. If you are new to R, we highly recommend using RStudio. It will make your learning experience much easier.\nHere are some additional details about RStudio:\n\nIt is available for Windows, macOS, and Linux.\nIt is free to use for personal use.\nThere is a paid version of RStudio that includes additional features, such as a cloud-based IDE and a subscription to the RStudio Pro services.\n\n\n\n\n\nRstudio\n\n\n\nThe functions of these different sections are as follows:\n\nA: Source file editing window. Here you can edit your script file, select parts and execute them with Ctrl-Enter (Cmd-??? on Mac). Data table tabs are also displayed here.\nB: Environment window. This displays the list of objects you have created. These objects can be simple variables, tables, functions, graphical objects, etc.\nC: Console. Here you can write command lines directly. Press Enter to execute a line you’ve just written. This is also where any error messages are displayed.\nD: Multi-tabbed window. Files is used to navigate through your computer’s file system, Plots displays graphics, Packages displays available and loaded packages (when checked). Help provides help on functions.\n\n\n\n1.1.2 Packages\n\n\n\n\nThe R packages galaxy\n\n\n\nA package in R is a collection of R code, data, and documentation that can be installed and used as a single unit. Packages are a great way to share code with others, and they can be used to extend the functionality of R.\nR packages are stored in the R Package Archive (CRAN), which is a central repository of R packages. Packages can be installed from CRAN using the install.packages() command.\nOnce a package has been installed, it can be loaded into the R environment using the library() command. Once a package has been loaded, its functions and data can be accessed.\nR packages are a powerful tool that can be used to improve the productivity and efficiency of statistical analyses.\n\ndplyr: This package is used for data manipulation. It provides a consistent and intuitive way to filter, select, mutate, and summarize data frames.\ntidyr: This package is used for tidying data. It provides a set of functions to help you transform your data into a format that is easy to work with.\nggplot2: This package is used for creating beautiful and informative graphics.\nreadr: This package is used for reading data into R. It provides a consistent and efficient way to read data from a variety of file formats.\nstringr: This package is used for working with strings. It provides a set of functions to help you manipulate, search, and parse strings.\nlubridate: This package is used for working with dates and times. It provides a set of functions to help you parse, manipulate, and format dates and times.\npurrr: This package is used for functional programming. It provides a set of functions that make it easy to write concise and elegant code.\nforcats: This package is used for working with factors. It provides a set of functions to help you manipulate, summarize, and visualize factors.\n\nThese are just a few of the many R packages that are available. There are packages for almost everything you can think of, from machine learning to statistical modeling to visualization.\n\n\n1.1.3 An object-oriented programming language\nAs Python, R is an object-oriented programming language, that is to say a programming paradigm based on the concept of objects, which can contain data and code. Objects in R can be vectors, matrices, arrays, data frames, tables and list.\nEvery time you see this symbol &lt;-, it means that R is creating an object that it will keep in memory. So, if I do this A &lt;- 6, A will have become an object, and logically sqrt(A) will be equal to \\(\\sqrt{6}\\).\n\n\n1.1.4 Some references\n\nR Tutorial: Excellent for beginners. All the software’s basic functions are covered very simply.\nR for Data Science: Perhaps the best-known reference for all data scientists working with R. By Wickham, Çetinkaya-Rundel, and Grolemund (2023) Very comprehensive!\nVisualization with ggplot2: A very good summary of the DataViz techniques possible with the ggplot2 package."
  },
  {
    "objectID": "intro.html#how-this-tutorial-works",
    "href": "intro.html#how-this-tutorial-works",
    "title": "1  Introduction",
    "section": "1.2 How this tutorial works?",
    "text": "1.2 How this tutorial works?\nVery simply! You just have to copy/paste and… run the code.\n\n10*(1+1+1.5)  # = 35         # calculus\n10**2         # = 100        # square\n10^2          # idem\n100**(1/2)    # = 10         # power\n100^(1/2)     # idem\n\nYou should have this:\n\n\n[1] 35\n\n\n[1] 100\n\n\n[1] 100\n\n\n[1] 10\n\n\n[1] 10\n\n\nWhat we see here is the basic calculation made with R. Note that the # symbol allows you to add comments to the code without them being executed by the program.\nIn addition to basic calculation, R has all the usual predefined functions in stock:\n\nsqrt(100)     # root  \npi            # pi  \ncos(pi)       # cos\nsin(pi/2)     # sin\nexp(1)        # exponential\nlog(1)        # log \n\n\n\n[1] 10\n\n\n[1] 3.141593\n\n\n[1] -1\n\n\n[1] 1\n\n\n[1] 2.718282\n\n\n[1] 0\n\n\nBut also functions: here, the round() function, which rounds a number to the desired number of decimal places (You can see the complete list of functions here):\n\nround(2.566)     # round\n\n[1] 3\n\nround(pi,0)      # idem \n\n[1] 3\n\nround(pi,2)      # with 2 decimals\n\n[1] 3.14\n\n\nThink you’ve got it? Let’s find out. Try to calculate the following formula, in principle you should find -0.02 to two decimal places.\n\\[  \\frac{sin(\\sqrt \\pi )+cos^2(5)}{3-e^4}   \\]\n\n\n\n\n\n\nSee solution\n\n\n\n\n\n\n(sin(sqrt(pi))+(cos(5))^2)/(3-exp(4))\n\n[1] -0.02054725"
  },
  {
    "objectID": "intro.html#learning-by-doing",
    "href": "intro.html#learning-by-doing",
    "title": "1  Introduction",
    "section": "1.3 Learning by doing",
    "text": "1.3 Learning by doing\nThe time has come to get down to business. In this game, you’re the hero. You’ll have to execute every line of the following code and figure out for yourself what’s going on… Go to work!\n\na &lt;- 100\na\nprint(a)\n\nv &lt;- c(10,20,30)  #  vector\nv\nlength(v)         # lenght vector\n\nlength(a)\nis.vector(a)\n\n2*v+1             # on any composant of vector\nv**2              # \nlog(v)            # \n\nw &lt;- c(1,2,3)     # \nv-w               # \nv*w               # \nv/w               #  \nv%*%w             # \n\nsum(v)         # = 60  \nmean(v)        # = 20  \nmin(v)         # = 10  \nmax(v)         # = 30   \nsd(v)          # = 10  \nmedian(v)      # = 20  \n\nu &lt;- c(1,2,3,4,5,6,7,8) # \nu[2]                    # \n\nu[3:5]                  # \n# \n\nu[8] &lt;- 80              # \nu\n\nu[1:5] &lt;- 1             #            \nu"
  },
  {
    "objectID": "intro.html#exercices",
    "href": "intro.html#exercices",
    "title": "1  Introduction",
    "section": "1.4 Exercices",
    "text": "1.4 Exercices\n\nHow do you load the tidyverse package? \nWhat package helps you load CSV files? tidyrdplyrreadrggplot2\nWhich package to create beautiful graphics? tidyrdplyrggplot2shiny\nHow do I create an “empty vector” object named “Empty_Vect”? \nThis course is very cool TRUEFALSE\n\n\n\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science. \" O’Reilly Media, Inc.\"."
  },
  {
    "objectID": "summary.html#what-is-a-database",
    "href": "summary.html#what-is-a-database",
    "title": "2  Example",
    "section": "2.1 What is a database?",
    "text": "2.1 What is a database?\nLet’s start with an example that has nothing to do with economics.. Here a picture of our beautiful Toulouse:\n\n\n\n\nToulouse, France\n\n\n\n\nIn fact, this picture is just a database made of pixels. A huge database of \\(1186 \\times883=1 047 238\\) rows for only \\(3\\) columns… Each row corresponds to a pixel, and each column to a color intensity, ranging from 0 to 1 for the three basic colors: red , blue  and green .\n\n\n\n\nA pixel\n\n\n\n\nFor a computer, this image is simply the storage of 3,141,714 numbers between 0 and 1! To confirm this, we’ll ask R to convert an image into a database of numbers between 0 and 1. Run the following code:\n\n\ninstall.packages(\"jpeg\")\ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)\nlibrary(jpeg)\n\n#Import a JPEG file\nraw=readJPEG(file.choose())\n\n# Transform in a dataframe\nmyImage=as.data.frame(array(raw,dim=c(dim(raw)[1]*dim(raw)[2], dim(raw)[3])))\n\ncolnames(myImage)=c(\"R\", \"G\", \"B\")\nView(myImage)\n\n Note that the line raw=readJPEG(file.choose()) allows you to choose directly a file in your computer.\nThe line View(myImage) will show you the database with numbers. Here are the first 100 raws:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe first line shows the values of the first pixel, i.e. the one in the top left-hand corner. We can see that at this point, the Occitan sky is very blue, which seems to be confirmed by the blue values (equal to 1, the maximum intensity). There’s no red at all, and green is 0.7. As we move down the image, it will become less and less blue, and we’ll see the values of this color decrease, while red will gain in intensity."
  },
  {
    "objectID": "summary.html#first-data-manipulation",
    "href": "summary.html#first-data-manipulation",
    "title": "2  Example",
    "section": "2.2 First Data Manipulation",
    "text": "2.2 First Data Manipulation\nLet’s start by simulating a nuclear attack: all the pixels in the database should turn completely green, i.e. G=1. To do this, we’ll create a new object MyImage2 where we’ll set all the values in column G to 1.\nThe easiest way to do so is to use the $ symbol. For R, the $ symbol will reach a specific column while not changing the others. The myImage2$G &lt;- 1 command will therefore set all green pixels to maximum and leave the others unchanged.\n\nmyImage2 &lt;- myImage\n\nmyImage2$G &lt;- 1\n\n# Reshape in a matrix format\nmy2=array(as.matrix(myImage2), dim=c(dim(raw)[1], dim(raw)[2], dim(raw)[3]))\n\n\nwriteJPEG(my2, file.choose())\n\n\n\n\n\n\n\n\nImportant\n\n\n\nyou have to write your file as yourfile.jpeg when your browser will ask you the place to put the picture with the command writeJPEG(my2, file.choose()).\n\n\nYou should obtain something like this: \n\n\n\n\nToulouse with all green\n\n\n\n\nNote that transforming an image into black and white is very simple. All you have to do is set the same value for the three colors for each pixel. For example, by doing myImage$R &lt;- myImage$B and myImage$G &lt;- myImage$B, such that all pixels take the blue value. We obtain:\n\n\n\n\n\nToulouse in black and white"
  },
  {
    "objectID": "summary.html#techniques",
    "href": "summary.html#techniques",
    "title": "2  Example",
    "section": "2.3 Techniques",
    "text": "2.3 Techniques\n\n2.3.1 data[,] versus - data$\n\ndata[,] is a two-dimensional array that allows you to access rows and columns of a data frame. The first set of square brackets [] specifies the rows, and the second set specifies the columns. For example, myImage[1,] will return the first row (pixel) of the data frame, and myImage[,2] will return the second column (all green pixels).\ndata$ is a one-dimensional vector that allows you to access a column of a data frame by name. For example, myImage$R will return the name column R of the data frame.\n\nThe main difference between the two structures is that data[,] allows you to access rows and columns by position, while data$ allows you to access columns by name.\nFor example, let’s suppose you want to blacken all pixels between 1 and 300000. How do we do this? Very simply, set all lines between 1 and 300000 to 0 using this code:\nmyImage[1:300000,]&lt;-c(0,0,0)\n\n\n\n\n\nToulouse cut\n\n\n\n\n\n\n2.3.2 ifelse()\nLet’s suppose we want to lower the red intensity a little, say \\(-0.1\\) for all pixels. It would be quite simple to execute the command myImage$R &lt;- myImage$R - 0.1. But there’s a problem: for values between \\(0\\) and \\(0.1\\), we’d have negative numbers, which makes no sense when it comes to recompiling the whole thing in pixel intensity, and a bug will arise. This is where the ifelse function comes into its own: This will allow us to change the values in column R under certain conditions. Here, we want to remove \\(0.1\\) from everyone except the values between \\(0\\) and \\(0.1\\), which will be fixed at \\(0\\). Here’s the code:\n\nmyImage5 &lt;- myImage\n\nmyImage5$R &lt;- ifelse(myImage5$R -0.1 &lt; 0,0,myImage5$R -0.1)"
  },
  {
    "objectID": "summary.html#learning-by-doing",
    "href": "summary.html#learning-by-doing",
    "title": "2  Example",
    "section": "2.4 Learning by Doing",
    "text": "2.4 Learning by Doing\nHow do I select the bottom-left pixel?\n\n\n\n\n\n\nSee solution\n\n\n\n\n\n\nPixel_left &lt;- myImage[883,]\n\n\n\n\nWhat is the code for symmetrically placing the black rectangle on the right-hand side?\n\n\n\n\n\n\nSee solution\n\n\n\n\n\n\nmyImage[747238:1047238,]&lt;-c(0,0,0)\n\n\n\n\nWhat if I want to increase the intensity of the blues by 0.2 units?\n\n\n\n\n\n\nSee solution\n\n\n\n\n\n\nmyImage$B &lt;- ifelse(myImage$B  &gt;0.8,1,myImage$B +0.2)\n\n\n\n\nCan you fill in the top half of the image in white?\n\n\n\n\n\n\nHint\n\n\n\n\n\nThis is more difficult. In fact, it’s a question of finding a link between all the pixels located in the upper half of the image. As the image contains 883 elements per column, the first column has pixel number 441 as half. Then we’d have to select pixel 884 in the second column up to 884+441 etc…\nGood luck!"
  },
  {
    "objectID": "summary.html#exercices",
    "href": "summary.html#exercices",
    "title": "2  Example",
    "section": "2.5 Exercices",
    "text": "2.5 Exercices\n\nSelect the first 100 rows and the second column of myImage: \nWhich of the following code will return the rows where the blues are greater than 0.8?? myImage[data &gt; 0.8,]myImage[B &gt; 0.8,]myImage[,B &gt; 0.8]data$[myImageB &gt; 0.8]\nWhich of the following code will change the red of the first row to 1? myImage[1,2] &lt;- 1 myImage[,2] &lt;- 1myImage[,2] = 1myImage$R[1] &lt;- 1\nHow can I access the first row (named X) of the data frame using data$? \nNice to know you can even manipulate photos with R TRUEFALSE"
  },
  {
    "objectID": "DataI.html#tidy-or-not-tidy-that-is-the-question..",
    "href": "DataI.html#tidy-or-not-tidy-that-is-the-question..",
    "title": "3  Data I",
    "section": "3.1 Tidy or not Tidy? That is the question..",
    "text": "3.1 Tidy or not Tidy? That is the question..\nTidy data is essential for a data scientist. But what do we mean by “tidy”? As you can see from the cheatsheet, a dataset is said to be tidy if each row corresponds to a single observation, and each variable to its own column. In the dataset you’ve just downloaded, it’s clear that one row represents 18 observations, comprising the 18 years studied. A lot of statistical software won’t like this…\nIndeed, tidy data is a standard way of mapping the meaning of a dataset to its structure. In tidy data we have :\n\nEvery column is a variable.\nEvery row is an observation.\nEvery cell is a single value.\n\nThis is Codd’s 3rd normal form. Messy data is any other arrangement of the data.\n\nSo we need to change this first, by changing the columns to rows. Technically speaking, this will multiply the number of rows by 18… Excel by hand will take all day! But fortunately for us, R has the magic solution: the gather()function. Run the following code:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndf &lt;- gather(population1,year,pop,2:20)\nhead(df)\n\n# A tibble: 6 × 3\n  country        year       pop\n  &lt;chr&gt;          &lt;chr&gt;    &lt;dbl&gt;\n1 Afghanistan    1995  17586073\n2 Albania        1995   3357858\n3 Algeria        1995  29315463\n4 American Samoa 1995     52874\n5 Andorra        1995     63854\n6 Angola         1995  12104952\n\n\n\nNot TidyTidy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncountry\n1995\n1996\n1997\n1998\n1999\n2000\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n\n\n\n\nAfghanistan\n17586073\n18415307\n19021226\n19496836\n19987071\n20595360\n21347782\n22202806\n23116142\n24018682\n24860855\n25631282\n26349243\n27032197\n27708187\n28397812\n29105480\n29824536\n30551674\n\n\nAlbania\n3357858\n3341043\n3331317\n3325456\n3317941\n3304948\n3286084\n3263596\n3239385\n3216197\n3196130\n3179573\n3166222\n3156608\n3151185\n3150143\n3153883\n3162083\n3173271\n\n\nAlgeria\n29315463\n29845208\n30345466\n30820435\n31276295\n31719449\n32150198\n32572977\n33003442\n33461345\n33960903\n34507214\n35097043\n35725377\n36383302\n37062820\n37762962\n38481705\n39208194\n\n\nAmerican Samoa\n52874\n53926\n54942\n55899\n56768\n57522\n58176\n58729\n59117\n59262\n59117\n58652\n57919\n57053\n56245\n55636\n55274\n55128\n55165\n\n\nAndorra\n63854\n64274\n64090\n63799\n64084\n65399\n68000\n71639\n75643\n79060\n81223\n81877\n81292\n79969\n78659\n77907\n77865\n78360\n79218\n\n\nAngola\n12104952\n12451945\n12791388\n13137542\n13510616\n13924930\n14385283\n14886574\n15421075\n15976715\n16544376\n17122409\n17712824\n18314441\n18926650\n19549124\n20180490\n20820525\n21471618\n\n\nAnguilla\n9807\n10063\n10305\n10545\n10797\n11071\n11371\n11693\n12023\n12342\n12637\n12903\n13145\n13365\n13571\n13768\n13956\n14132\n14300\n\n\nAntigua and Barbuda\n68349\n70245\n72232\n74206\n76041\n77648\n78972\n80030\n80904\n81718\n82565\n83467\n84397\n85349\n86300\n87233\n88152\n89069\n89985\n\n\nArgentina\n34833168\n35264070\n35690778\n36109342\n36514558\n36903067\n37273361\n37627545\n37970411\n38308779\n38647854\n38988923\n39331357\n39676083\n40023641\n40374224\n40728738\n41086927\n41446246\n\n\nArmenia\n3223173\n3173425\n3137652\n3112958\n3093820\n3076098\n3059960\n3047002\n3036032\n3025652\n3014917\n3002911\n2989882\n2977488\n2968154\n2963496\n2964120\n2969081\n2976566\n\n\nAruba\n80326\n83195\n85447\n87276\n89004\n90858\n92894\n94995\n97015\n98742\n100031\n100830\n101219\n101344\n101418\n101597\n101932\n102384\n102911\n\n\nAustralia\n18124234\n18339037\n18563442\n18794552\n19027438\n19259377\n19487257\n19714625\n19953121\n20218481\n20520736\n20865583\n21246274\n21645095\n22037143\n22404488\n22740536\n23050471\n23342553\n\n\nAustria\n7985372\n8009345\n8014124\n8009051\n8007843\n8020262\n8049440\n8091804\n8142322\n8193157\n8238604\n8277393\n8311463\n8342129\n8371711\n8401924\n8432890\n8463948\n8495145\n\n\nAzerbaijan\n7770806\n7852273\n7921745\n7984460\n8047936\n8117742\n8195427\n8279768\n8370169\n8465127\n8563398\n8665006\n8770122\n8877669\n8986266\n9094718\n9202432\n9308959\n9413420\n\n\nBahamas\n280050\n283678\n286845\n289926\n293442\n297759\n303005\n309039\n315624\n322400\n329088\n335622\n342049\n348340\n354492\n360498\n366331\n371960\n377374\n\n\n\n\n\n\n\n\n\n\n\n\ncountry\nyear\npop\n\n\n\n\nAfghanistan\n1995\n17586073\n\n\nAlbania\n1995\n3357858\n\n\nAlgeria\n1995\n29315463\n\n\nAmerican Samoa\n1995\n52874\n\n\nAndorra\n1995\n63854\n\n\nAngola\n1995\n12104952\n\n\nAnguilla\n1995\n9807\n\n\nAntigua and Barbuda\n1995\n68349\n\n\nArgentina\n1995\n34833168\n\n\nArmenia\n1995\n3223173\n\n\nAruba\n1995\n80326\n\n\nAustralia\n1995\n18124234\n\n\nAustria\n1995\n7985372\n\n\nAzerbaijan\n1995\n7770806\n\n\nBahamas\n1995\n280050\n\n\n\n\n\n\n\n\n So here we’ve created a “df” object that simply puts every observation of a year on a country on a single row. We told R the names of the new columns, “year” and “pop” and the column numbers (from 2 to 20) where to apply the gather() function. And we’ve got a tidy dataset with only 3 columns!"
  },
  {
    "objectID": "DataI.html#merge-2-datasets",
    "href": "DataI.html#merge-2-datasets",
    "title": "3  Data I",
    "section": "3.2 Merge 2 datasets",
    "text": "3.2 Merge 2 datasets\nDownload the second database:\n\n\n\n\n\n\n\n\nOnce the data has been ordered, a second very common problem for anyone working with data is the merging of different databases. Indeed, with information coming from everywhere these days, it’s rare to start work with a nice, clean and unique database.\nIn most cases, you’ll have to draw on other data! This means merging the databases on a common criterion, which we’ll call a key. In the cheatsheet, the key is x1 and is a variable name in the two bases. As you can see, there is 4 different ways to merge data in R:\n\n\n\n\nFor instance, the command left_join(a,b,by=\"x1\") will take all the elements that have x1 in common from b and stick them to a.\nIn our example, we now have two databases: a well-ordered one containing the population of each country between the years 1995 and 2013, the other containing other information about the countries, such as the language spoken, the currency used etc… Before any analysis, we need to merge them. And the only common criterion between these two bases is the name of the country wich will become our key.\nThus, to merge the two bases we will run this simple code:\n\ndf2 &lt;- population2\ncolnames(df2)[2] &lt;- \"country\" # To have the same column name\ndf3 &lt;- left_join(df,df2, by =\"country\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncountry\nyear\npop\nCode\nNative\nPhone\nContinent\nCapital\nCurrency\nLanguages\n\n\n\n\nAfghanistan\n1995\n17586073\nAF\nافغانستان\n93\nAsia\nKabul\nAFN\nps,uz,tk\n\n\nAlbania\n1995\n3357858\nAL\nShqipëria\n355\nEurope\nTirana\nALL\nsq\n\n\nAlgeria\n1995\n29315463\nDZ\nالجزائر\n213\nAfrica\nAlgiers\nDZD\nar\n\n\nAmerican Samoa\n1995\n52874\nAS\nAmerican Samoa\n1684\nOceania\nPago Pago\nUSD\nen,sm\n\n\nAndorra\n1995\n63854\nAD\nAndorra\n376\nEurope\nAndorra la Vella\nEUR\nca\n\n\nAngola\n1995\n12104952\nAO\nAngola\n244\nAfrica\nLuanda\nAOA\npt\n\n\nAnguilla\n1995\n9807\nAI\nAnguilla\n1264\nNorth America\nThe Valley\nXCD\nen\n\n\nAntigua and Barbuda\n1995\n68349\nAG\nAntigua and Barbuda\n1268\nNorth America\nSaint John’s\nXCD\nen\n\n\nArgentina\n1995\n34833168\nAR\nArgentina\n54\nSouth America\nBuenos Aires\nARS\nes,gn\n\n\nArmenia\n1995\n3223173\nAM\nՀայաստան\n374\nAsia\nYerevan\nAMD\nhy,ru\n\n\nAruba\n1995\n80326\nAW\nAruba\n297\nNorth America\nOranjestad\nAWG\nnl,pa\n\n\nAustralia\n1995\n18124234\nAU\nAustralia\n61\nOceania\nCanberra\nAUD\nen\n\n\nAustria\n1995\n7985372\nAT\nÖsterreich\n43\nEurope\nVienna\nEUR\nde\n\n\nAzerbaijan\n1995\n7770806\nAZ\nAzərbaycan\n994\nAsia\nBaku\nAZN\naz\n\n\nBahamas\n1995\n280050\nBS\nBahamas\n1242\nNorth America\nNassau\nBSD\nen\n\n\n\n\n\n\nGreat! We can now work on a full tidy dataset."
  },
  {
    "objectID": "DataI.html#manipulating-data",
    "href": "DataI.html#manipulating-data",
    "title": "3  Data I",
    "section": "3.3 Manipulating Data",
    "text": "3.3 Manipulating Data\n\n3.3.1 ==\nNow assume we want to keep only a few variable. To erase columns, try for instance df4 &lt;- select(df3,-c(Code,Native,Phone,Capital))\n\n\n\n\n\n\nImportant\n\n\n\nTry to work with column names rather than column numbers. If you have to repeat the code and you’ve deleted column number 2, the new column number 2 (which was previously number 3) will also be deleted… And don’t put spaces in column names!\n\n\nR also provides a suite of comparison operators that you can use to compare values: &gt;, &gt;=, &lt;, &lt;=, != (not equal), and == (equal). Each creates a logical test. For example, Which European countries have populations of less than 10.000.000??\n\ndf5 &lt;- filter(df4, Continent==\"Europe\", Population &lt;= 10000000)\n\n\n\n3.3.2 &, |, and !\nR uses boolean operators to combine multiple logical comparisons into a single logical test. These include & (and), | (or), ! (not or negation), and xor() (exactly or).\nBoth | and xor() will return TRUE if one or the other logical comparison returns TRUE. xor() differs from | in that it will return FALSE if both logical comparisons return TRUE. The name xor stands for exactly or.\nWhen you place a logical test inside of filter(), filter applies the test to each row in the data frame and then returns the rows that pass, as a new data frame.\n\n\n\n\n\n\nImportant\n\n\n\nWhen you start out with R, the easiest mistake to make is to test for equality with = instead of ==. When this happens you’ll get an informative error."
  },
  {
    "objectID": "DataI.html#learning-by-doing",
    "href": "DataI.html#learning-by-doing",
    "title": "3  Data I",
    "section": "3.4 Learning by doing",
    "text": "3.4 Learning by doing\nIt’s up to you! Starting from the last dataset df4 and using the Group Data part of the cheatsheet, run each line of the following codes, then answer the three questions.\n\ndf5 &lt;- filter(df4, Continent==\"Europe\", Currency==\"EUR\")\n\n# Filter country in America\ndf6 &lt;- filter(df4, grepl('South America|North America', Continent))\n\n# Filter on top 3\ndf6 &lt;- df4 %&gt;% group_by(country, year) %&gt;%  top_n(3, pop) %&gt;% arrange(desc(pop))\ndf7 &lt;- df4 %&gt;% group_by(country) %&gt;%  top_n(3, pop) %&gt;% arrange(desc(pop))\n\n# Most populated top 5 country by continent\ndf8 &lt;- df4 %&gt;% group_by(country, Continent) %&gt;%  top_n(5, pop) %&gt;% arrange(desc(pop))\n\n\n\ndf_final &lt;- spread(population,year,population)\nwrite.xlsx(df1, file = \"population.xlsx\")"
  },
  {
    "objectID": "DataI.html#exercices",
    "href": "DataI.html#exercices",
    "title": "3  Data I",
    "section": "3.5 Exercices",
    "text": "3.5 Exercices\n\nWhat is the converse of the gather() function? \nWhat this code does df5 &lt;- filter(df4, Continent==\"Europe\", Currency==\"EUR\")? Filter df4 on european country that use EuroFilter df4 on european country or on contry that use EuroCreate a new object that keeps only european country that use EuroAn error\nWhat is the function of the pipe %&gt;%? Passes object on left hand side as first argumentPasses object on right hand side as first argumentBe indifferent in the code’s orders\nWhat function separates one column into several? ? \nIf I load the tidyverse package, I also need to load the dplyr package TRUEFALSE"
  },
  {
    "objectID": "dataii.html#general-instructions",
    "href": "dataii.html#general-instructions",
    "title": "4  Data II",
    "section": "4.1 General instructions",
    "text": "4.1 General instructions\nYou are an economist working for a government or private firm. You are provided with four databases, the first lines of which are as follows:\n\nCountryGDPInflationUnemployment\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nName\nNative\nPhone\nContinent\nCapital\nCurrency\nLanguages\n\n\n\n\nAD\nAndorra\nAndorra\n376\nEurope\nAndorra la Vella\nEUR\nca\n\n\nAE\nUnited Arab Emirates\nدولة الإمارات العربية المتحدة\n971\nAsia\nAbu Dhabi\nAED\nar\n\n\nAF\nAfghanistan\nافغانستان\n93\nAsia\nKabul\nAFN\nps,uz,tk\n\n\nAG\nAntigua and Barbuda\nAntigua and Barbuda\n1268\nNorth America\nSaint John’s\nXCD\nen\n\n\nAI\nAnguilla\nAnguilla\n1264\nNorth America\nThe Valley\nXCD\nen\n\n\nAL\nAlbania\nShqipëria\n355\nEurope\nTirana\nALL\nsq\n\n\nAM\nArmenia\nՀայաստան\n374\nAsia\nYerevan\nAMD\nhy,ru\n\n\nAO\nAngola\nAngola\n244\nAfrica\nLuanda\nAOA\npt\n\n\nAQ\nAntarctica\nAntarctica\n672\nAntarctica\n\n\n\n\n\nAR\nArgentina\nArgentina\n54\nSouth America\nBuenos Aires\nARS\nes,gn\n\n\nAS\nAmerican Samoa\nAmerican Samoa\n1684\nOceania\nPago Pago\nUSD\nen,sm\n\n\nAT\nAustria\nÖsterreich\n43\nEurope\nVienna\nEUR\nde\n\n\nAU\nAustralia\nAustralia\n61\nOceania\nCanberra\nAUD\nen\n\n\nAW\nAruba\nAruba\n297\nNorth America\nOranjestad\nAWG\nnl,pa\n\n\nAX\nÅland\nÅland\n358\nEurope\nMariehamn\nEUR\nsv\n\n\n\n\n\n\n Download Country as csv\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncountry\nCountry Code\n1960\n1961\n1962\n1963\n1964\n1965\n1966\n1967\n1968\n1969\n1970\n1971\n1972\n1973\n1974\n1975\n1976\n1977\n1978\n1979\n1980\n1981\n1982\n1983\n1984\n1985\n1986\n1987\n1988\n1989\n1990\n1991\n1992\n1993\n1994\n1995\n1996\n1997\n1998\n1999\n2000\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n\n\n\n\nAruba\nABW\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n405586592\n487709497\n596648045\n695530726\n764804469\n872067039\n958659218\n1083240223\n1245810056\n1320670391\n1379888268\n1531843575\n1665363128\n1722905028\n1873184358\n1896648045\n1962011173\n2044134078\n2.254749e+09\n2.359777e+09\n2.469832e+09\n2.677654e+09\n2.843017e+09\n2.553631e+09\n2.453631e+09\n2.637989e+09\n2.615084e+09\n2.727933e+09\n2.791061e+09\n2.963128e+09\n2.983799e+09\n3.092179e+09\n3.276188e+09\n3.395794e+09\n2.610039e+09\n3.126019e+09\nNA\n\n\nAfrica Eastern and Southern\nAFE\n21125015452\n21616228139\n23506279900\n28048360188\n25920665260\n29472103270\n32014368121\n33269509510\n36327785495\n41638967621\n44629891649\n49173371529\n53123459912\n69482723444\n85380645042\n90835426418\n90212747243\n102240575583\n116084638702\n134256827127\n171217790781\n175859256874\n168095657215\n175564912386\n160646748724\n136759437910\n153050335916\n186658478814\n204765985926\n218241607366\n254062093242\n276856728336\n246088124936\n242926405780\n239610677917\n270327154575\n269490833465\n283446224788\n266652333831\n263024788890\n284759318603\n259643121973\n266529432166\n354176768091\n4.404818e+11\n5.139416e+11\n5.775869e+11\n6.628680e+11\n7.105362e+11\n7.219012e+11\n8.635195e+11\n9.678246e+11\n9.753548e+11\n9.859871e+11\n1.006526e+12\n9.273485e+11\n8.851764e+11\n1.021043e+12\n1.007196e+12\n1.000834e+12\n9.275933e+11\n1.081998e+12\n1.169484e+12\n\n\nAfghanistan\nAFG\n537777811\n548888896\n546666678\n751111191\n800000044\n1006666638\n1399999967\n1673333418\n1373333367\n1408888922\n1748886596\n1831108971\n1595555476\n1733333264\n2155555498\n2366666616\n2555555567\n2953333418\n3300000109\n3697940410\n3641723322\n3478787909\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n3854235264\n4539496563\n5.220825e+09\n6.226199e+09\n6.971383e+09\n9.715765e+09\n1.024977e+10\n1.215484e+10\n1.563384e+10\n1.819041e+10\n2.020357e+10\n2.056449e+10\n2.055058e+10\n1.999814e+10\n1.801955e+10\n1.889635e+10\n1.841886e+10\n1.890450e+10\n2.014345e+10\n1.458314e+10\nNA\n\n\nAfrica Western and Central\nAFW\n10447637853\n11173212080\n11990534018\n12727688165\n13898109284\n14929792388\n15910837742\n14510579889\n14968235782\n16979315745\n23596163865\n20936358634\n25386169423\n31975594565\n44416677335\n51667190242\n62351622300\n65595122956\n71496496574\n88948338390\n112439126385\n211338060015\n187448724920\n138384182007\n114516348921\n116776995133\n107886511309\n110728825942\n109438851254\n102254998563\n122387353859\n118039698016\n118893094122\n99272180411\n86636400266\n108690885030\n126287285163\n127602388366\n130678128885\n138085971820\n140945759314\n148529518712\n177201164643\n205214466071\n2.542648e+11\n3.108896e+11\n3.969210e+11\n4.654855e+11\n5.677912e+11\n5.083627e+11\n5.985216e+11\n6.820159e+11\n7.375895e+11\n8.339481e+11\n8.943225e+11\n7.686447e+11\n6.913634e+11\n6.848988e+11\n7.670257e+11\n8.225384e+11\n7.864600e+11\n8.444597e+11\n8.778633e+11\n\n\nAngola\nAGO\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n5930503401\n5550483036\n5550483036\n5784341596\n6131475065\n7554065410\n7072536109\n8084412414\n8769836769\n10201780977\n11229515599\n12704558517\n15114352005\n11051939102\n3390500000\n5561222222\n7526963964\n7648377413\n6506229607\n6152922943\n9129594819\n8936079253\n15285592487\n17812704626\n2.355206e+10\n3.697090e+10\n5.238103e+10\n6.526642e+10\n8.853866e+10\n7.030720e+10\n8.169953e+10\n1.094366e+11\n1.249982e+11\n1.334016e+11\n1.372444e+11\n8.721930e+10\n4.984049e+10\n6.897277e+10\n7.779294e+10\n6.930911e+10\n5.024137e+10\n6.568544e+10\n1.067136e+11\n\n\nAlbania\nALB\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1857338012\n1897050133\n2097326250\n2080796250\n2051236250\n2253090000\n2028553750\n1099559028\n652174991\n1185315468\n1880950858\n2392764853\n3199640826\n2258513974\n2545964541\n3212121651\n3480355258\n3922100794\n4348068242\n5611496257\n7.184686e+09\n8.052077e+09\n8.896075e+09\n1.067732e+10\n1.288135e+10\n1.204421e+10\n1.192693e+10\n1.289076e+10\n1.231983e+10\n1.277622e+10\n1.322815e+10\n1.138685e+10\n1.186120e+10\n1.301973e+10\n1.515642e+10\n1.540183e+10\n1.516273e+10\n1.793057e+10\n1.888210e+10\n\n\nAndorra\nAND\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n78617623\n89406588\n113414399\n150841573\n186557164\n220112880\n227284061\n253998001\n308020289\n411548366\n446377571\n388982990\n375914807\n327849981\n330073057\n346742876\n481996191\n611300147\n721425972\n795489464\n1028989394\n1106891025\n1209992650\n1007090915\n1017544675\n1178745314\n1224023416\n1180646068\n1211953954\n1239840270\n1429048106\n1546912332\n1755989899\n2361635782\n2.895048e+09\n3.159827e+09\n3.456265e+09\n3.952398e+09\n4.085782e+09\n3.674188e+09\n3.449926e+09\n3.629134e+09\n3.188653e+09\n3.193513e+09\n3.271686e+09\n2.789881e+09\n2.896610e+09\n3.000162e+09\n3.218420e+09\n3.155149e+09\n2.891001e+09\n3.325145e+09\n3.352033e+09\n\n\nArab World\nARB\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n34715404211\n37827652252\n42768536551\n49428519673\n58935857749\n74780454402\n142137633613\n157069227731\n195513756716\n225676459936\n249608263403\n337961752415\n459804598569\n474812142540\n444575870914\n418462069814\n425899415742\n419485435098\n406982702170\n440607629312\n424896194403\n455822667745\n644062569660\n471800078473\n473811268024\n482764256147\n507764942793\n556046395850\n614186085021\n662308062161\n649192024191\n717469440494\n820185610129\n802881110720\n807961558720\n893818030124\n1.062737e+12\n1.304401e+12\n1.545539e+12\n1.797932e+12\n2.263029e+12\n1.987053e+12\n2.334638e+12\n2.555979e+12\n2.801698e+12\n2.859669e+12\n2.905733e+12\n2.554156e+12\n2.537537e+12\n2.637112e+12\n2.843476e+12\n2.868891e+12\n2.533377e+12\n2.928456e+12\n3.557557e+12\n\n\nUnited Arab Emirates\nARE\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n14720728252\n19213156353\n24871775165\n23775765254\n31225660993\n43599160062\n49333424149\n46622718618\n42803323357\n41807954241\n40603650232\n33943612095\n36384908744\n36275674203\n41464995914\n50701443748\n51552165622\n54239171888\n55625170253\n59305093980\n65743666576\n73571233996\n78839008445\n75674336283\n84445473111\n104337372362\n103311640572\n109816201498\n124346358067\n1.478244e+11\n1.806175e+11\n2.221165e+11\n2.579161e+11\n3.154746e+11\n2.535474e+11\n2.897875e+11\n3.506661e+11\n3.846101e+11\n4.002185e+11\n4.141054e+11\n3.702755e+11\n3.692553e+11\n3.905168e+11\n4.270494e+11\n4.179897e+11\n3.494730e+11\n4.150216e+11\n5.075349e+11\n\n\nArgentina\nARG\nNA\nNA\n24450604878\n18272123664\n25605249382\n28344705967\n28630474728\n24256667553\n26436857247\n31256284544\n31584210366\n33293199095\n34733000536\n52544000117\n72436777342\n52438647922\n51169499892\n56781000101\n89049453088\n69252328952\n76961923741\n78676842367\n84307486837\n103979106778\n116915052107\n88150891728\n105872372614\n108810885301\n126890235049\n76629728760\n141352630147\n189719984268\n228778994288\n236741715015\n257440000000\n258031750000\n272149750000\n292859000000\n298948250000\n283523000000\n284203750000\n268696750000\n97724004252\n127586973492\n1.646579e+11\n1.987371e+11\n2.325573e+11\n2.875305e+11\n3.615580e+11\n3.329765e+11\n4.236274e+11\n5.301582e+11\n5.459824e+11\n5.520251e+11\n5.263197e+11\n5.947493e+11\n5.575323e+11\n6.436284e+11\n5.248199e+11\n4.477547e+11\n3.855404e+11\n4.872271e+11\n6.327703e+11\n\n\nArmenia\nARM\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n2256838858\n2069870130\n1272835453\n1201312829\n1315158637\n1468317435\n1596968946\n1639492445\n1893726437\n1845482173\n1911563669\n2118467913\n2376335048\n2807061009\n3.576615e+09\n4.900470e+09\n6.384452e+09\n9.206301e+09\n1.166204e+10\n8.647937e+09\n9.260286e+09\n1.014211e+10\n1.061932e+10\n1.112146e+10\n1.160951e+10\n1.055334e+10\n1.054614e+10\n1.152746e+10\n1.245794e+10\n1.361929e+10\n1.264170e+10\n1.386141e+10\n1.950278e+10\n\n\nAmerican Samoa\nASM\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n512000000\n524000000\n5.090000e+08\n5.000000e+08\n4.930000e+08\n5.180000e+08\n5.600000e+08\n6.750000e+08\n5.730000e+08\n5.700000e+08\n6.400000e+08\n6.380000e+08\n6.430000e+08\n6.730000e+08\n6.710000e+08\n6.120000e+08\n6.390000e+08\n6.470000e+08\n7.160000e+08\n7.090000e+08\nNA\n\n\nAntigua and Barbuda\nATG\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n77496754\n87879341\n109079979\n131431027\n147841734\n164369279\n182144093\n208372846\n240923925\n290440141\n337174862\n398637728\n438794789\n459470370\n481707407\n499281481\n535174074\n589429630\n577281481\n633729630\n680618519\n727859259\n766200000\n826370370\n800481481\n814381481\n856396296\n9.197296e+08\n1.022963e+09\n1.157663e+09\n1.312759e+09\n1.370070e+09\n1.228330e+09\n1.148700e+09\n1.137637e+09\n1.199948e+09\n1.181448e+09\n1.249733e+09\n1.336693e+09\n1.436585e+09\n1.467956e+09\n1.604770e+09\n1.675404e+09\n1.416348e+09\n1.560519e+09\n1.757604e+09\n\n\nAustralia\nAUS\n18606562979\n19682883152\n19922563190\n21539843449\n23801123811\n25976164159\n27307844373\n30442724874\n32714085238\n36683365874\n41333606618\n45216647240\n52042056075\n63832158873\n88963890936\n97304383449\n105060650224\n110350997935\n118491577919\n134898330115\n149984401114\n176891907582\n194037294494\n177263464408\n193517245510\n180634851530\n182472020145\n189487824246\n236152526239\n299875825287\n311430632641\n325981640935\n325532426233\n312138139404\n322809408509\n368140778141\n401310823653\n435613768960\n399660855999\n389389647826\n415844972940\n379357823193\n395573025330\n467497961561\n6.143264e+11\n6.953050e+11\n7.479074e+11\n8.544273e+11\n1.055686e+12\n9.286298e+11\n1.148570e+12\n1.398456e+12\n1.546953e+12\n1.576330e+12\n1.467590e+12\n1.350580e+12\n1.206563e+12\n1.326467e+12\n1.428267e+12\n1.392219e+12\n1.326945e+12\n1.552703e+12\n1.675419e+12\n\n\nAustria\nAUT\n6592693841\n7311749633\n7756110210\n8374175258\n9169983886\n9994070616\n10887682273\n11579431669\n12440625313\n13582798556\n15373005557\n17858486067\n22059612477\n29515467707\n35189299912\n40059206763\n42959976222\n51545758888\n62052259073\n73937296963\n82058912997\n71034228443\n71275287570\n72121016547\n67985344887\n69386774408\n99036164939\n124168442534\n133339397080\n133105805512\n166463386179\n173794177961\n195078126722\n190379720809\n203535242742\n241038283063\n237250948791\n212790348405\n218259904402\n217259147050\n197289625480\n197508773215\n214394866675\n262273631180\n3.014576e+11\n3.160923e+11\n3.362801e+11\n3.891856e+11\n4.320519e+11\n4.017587e+11\n3.922751e+11\n4.316852e+11\n4.094018e+11\n4.301910e+11\n4.425848e+11\n3.819711e+11\n3.958374e+11\n4.172612e+11\n4.549912e+11\n4.446212e+11\n4.352252e+11\n4.803684e+11\n4.714001e+11\n\n\n\n\n\n\n Download GDP as xls\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncountry\nCountry Code\n1961\n1962\n1963\n1964\n1965\n1966\n1967\n1968\n1969\n1970\n1971\n1972\n1973\n1974\n1975\n1976\n1977\n1978\n1979\n1980\n1981\n1982\n1983\n1984\n1985\n1986\n1987\n1988\n1989\n1990\n1991\n1992\n1993\n1994\n1995\n1996\n1997\n1998\n1999\n2000\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n\n\n\n\nAfrica Eastern and Southern\nAFE\n1.933947\n0.5990206\n3.003934\n3.905978\n3.432336\n4.120046\n2.039246\n3.397375\n5.361880\n4.690535\n4.126174\n10.451448\n12.224475\n13.94452\n12.099586\n10.109540\n10.256484\n10.751801\n15.180730\n22.026565\n10.853077\n7.6974718\n11.5568417\n11.1505446\n16.1443313\n13.5092842\n11.7357835\n20.0811009\n14.7982344\n11.9263048\n12.5319619\n14.2531377\n13.3768641\n10.9704267\n12.816518\n14.4531114\n9.0189407\n8.7857069\n8.0068133\n11.117306\n8.6299840\n9.4592650\n8.1127118\n9.839591\n7.407529\n8.5925531\n8.259570\n11.463040\n7.8998230\n6.1284324\n9.4302705\n6.9920163\n5.8441114\n5.7433139\n5.3664623\n6.4009005\n5.2174309\n3.980391\n4.7410077\n4.9385360\n6.0628624\n8.752940\n\n\nAfghanistan\nAFG\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n11.6552382\n11.271432\n10.912774\n7.1997513\n22.527756\n2.096289\n-2.1634044\n3.8146303\n16.5933467\n7.3017565\n4.8227855\n0.5669445\n2.4475630\n-2.1975265\n2.4036562\n2.071349\n6.5214798\n7.8216671\n0.4774289\nNA\n\n\nAfrica Western and Central\nAFW\n3.336148\n2.4326633\n3.013917\n2.906178\n2.752432\n4.143079\n1.280375\n2.031465\n4.838561\n3.710455\n4.189197\n5.145811\n7.198996\n13.42264\n8.586772\n12.054773\n11.043108\n7.667391\n11.173939\n11.978249\n10.625287\n13.8205590\n9.9279364\n11.3150500\n5.2972135\n0.0204678\n1.6845634\n3.4085566\n3.5848590\n6.6689419\n3.0734990\n0.7388168\n2.3783218\n25.0620438\n7.680834\n6.9072937\n3.6675092\n5.3873614\n7.6120782\n5.289805\n4.3199575\n2.2400607\n1.7188216\n5.681951\n6.688934\n4.6433221\n4.761878\n9.186759\n1.3962191\n5.0046653\n8.7898394\n4.7300948\n1.5713100\n0.2807881\n1.9349170\n1.7363231\n1.7591717\n3.365101\n1.5822896\n1.5673661\n6.4549132\n7.425749\n\n\nAngola\nAGO\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n-2.100306\n0.0000000\n0.0127636\n0.0011881\n19.0352057\n-9.0130619\n9.8233113\n2.2137744\n16.2796627\n14.0074398\n106.3099823\n476.5157509\n917.7834684\n2175.9789551\n1825.495149\n4800.5316442\n95.4530222\n39.3593483\n557.5011131\n418.018992\n106.3521255\n196.9840994\n93.9265669\n33.443595\n42.374249\n17.1156651\n4.308432\n19.365773\n-16.7621403\n32.2704691\n31.7714602\n7.2557499\n2.8397241\n3.5608848\n-3.5183853\n21.7743126\n22.6144365\n28.167093\n19.1870038\n10.7631053\n38.8290428\n16.300926\n\n\nAlbania\nALB\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n-2.139572\n-0.0177191\n-0.0167552\n-0.0283603\n0.3512223\n-2.4173004\n-0.0003061\n-0.0005786\n0.0036792\n-0.4313688\n35.5142470\n232.9846589\n125.6508142\n35.8424752\n9.970663\n38.1720582\n11.2396445\n6.7308599\n2.1028500\n5.647471\n3.8108574\n3.6474763\n5.1986353\n3.152369\n3.306818\n2.4781889\n4.386709\n4.117085\n2.4183361\n4.4931432\n2.3147438\n1.0427146\n0.2887460\n1.5499171\n0.5639914\n-0.6326534\n1.4507316\n1.472954\n1.2570248\n0.6965424\n3.4544320\n9.679621\n\n\nAndorra\nAND\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n7.845871\n8.518078\n11.849434\n15.94520\n16.781795\n16.489857\n23.383093\n20.631041\n16.931689\n13.354814\n12.351173\n13.5823498\n11.8842353\n10.8647344\n8.5954638\n10.8788153\n5.9441988\n5.9361250\n6.8962071\n7.3262437\n6.9351484\n6.7107690\n4.5372321\n3.8798583\n4.933121\n0.7971777\n2.2281603\n1.4995538\n2.7319795\n28.741553\n3.0805352\n3.2395318\n3.1774842\n3.042424\n3.396102\n3.4571841\n3.211227\n2.274338\n0.1321361\n0.3743138\n0.1967642\n0.1745569\n0.4484922\n-0.0840193\n0.6605890\n0.3477954\n1.1365093\n1.012479\n1.3747535\n1.1137861\n2.5595565\n4.213076\n\n\nArab World\nARB\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1.112976\n3.467698\n6.561872\n2.886724\n11.394036\n24.39473\n5.914022\n8.888893\n9.794715\n8.417213\n13.987838\n14.882020\n11.410748\n6.5297059\n7.2557988\n6.9812027\n4.9725264\n7.2602517\n8.8420204\n5.3831948\n8.7034145\n14.8265593\n7.9820513\n5.7167438\n4.6913434\n7.8737171\n6.678313\n5.0648196\n3.1084420\n-1.9244006\n6.6267786\n10.442345\n0.6942161\n3.9707477\n5.0162397\n11.023784\n15.355305\n9.8216053\n8.349756\n16.479241\n-5.7427465\n11.7967633\n14.2896432\n4.6707680\n1.5062098\n0.5252413\n-2.1149365\n0.9205895\n5.2529493\n7.341056\n2.3469124\n0.4083094\n12.6957152\n13.853415\n\n\nUnited Arab Emirates\nARE\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n11.774331\n5.255756\n-3.661112\n7.051020\n9.515976\n7.054484\n1.3128687\n-3.6180172\n-6.0974672\n0.7405329\n-1.6984853\n3.6855848\n2.3810457\n1.7512766\n3.3359005\n0.8108487\n1.8068261\n1.2780363\n-0.2624749\n3.907480\n5.7730439\n-0.9523007\n-4.2544453\n8.4433775\n11.459536\n-2.3493077\n3.7708395\n4.0724068\n8.501422\n16.526307\n11.9621493\n12.533961\n18.533353\n-15.1829799\n12.4901759\n13.1672194\n4.6797251\n-0.9493253\n-0.6680494\n-16.2670060\n-5.5294786\n4.9862131\n7.936748\n-3.1944094\n-12.0313053\n14.2808297\n13.853415\n\n\nArgentina\nARG\n20.310697\n28.8718416\n25.591154\n28.774617\n21.232935\n25.603462\n29.018263\n10.275311\n7.795830\n6.467875\n31.271064\n64.244786\n65.535287\n30.63044\n197.697364\n438.322780\n159.427178\n161.372172\n147.377044\n95.790425\n105.276366\n194.5352997\n380.1585285\n611.1963039\n607.4474978\n77.2922367\n127.5399181\n381.2463444\n3046.0911520\n2078.3168181\n140.5023787\n16.0719935\n-3.5610956\n2.8493397\n3.165123\n-0.0523755\n-0.4639131\n-1.7052796\n-1.8365584\n1.037287\n-1.0957677\n30.5552041\n10.4957030\n18.363354\n10.317511\n13.7410525\n14.939925\n23.171165\n15.3776494\n20.9151243\n23.7034722\n22.3148807\n23.9487984\n40.2829716\n26.5799916\n41.1193800\n26.0063793\n42.033669\n49.1955791\n40.0768830\n54.1524119\n69.682861\n\n\nArmenia\nARM\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n79.3861043\n568.8072954\n1391.1665432\n4107.2967699\n161.163918\n19.5917703\n17.7359945\n10.6984978\n0.0538041\n-1.373676\n4.0279695\n2.3573990\n4.5985157\n6.278594\n3.208757\n4.6180125\n4.277876\n5.989562\n2.4972531\n7.7687155\n4.2815500\n5.3458044\n3.3668246\n2.3091824\n1.2139099\n0.2685751\n2.1506419\n2.787710\n1.0656226\n1.8065927\n6.8667407\n8.062788\n\n\nAmerican Samoa\nASM\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1.3650529\n-3.259075\n-1.365583\n2.8136752\n3.160612\n11.059335\n25.7763975\n-15.3648896\n-0.5235602\n17.3684211\n2.2435897\n-0.9621603\n1.4697328\n1.4058217\n-1.9408901\n1.695361\n1.7482893\n5.3292983\n0.9054972\nNA\n\n\nAntigua and Barbuda\nATG\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n8.635282\n14.845488\n11.398779\n8.352614\n11.2726971\n5.1724824\n3.8442398\n7.4112599\n8.1249402\n8.8764445\n12.3705949\n4.5807066\n1.6504799\n2.6064018\n2.4612994\n1.8132339\n3.2445880\n2.403364\n2.9771844\n1.8272885\n2.1099070\n1.5042152\n1.553300\n1.4825883\n0.7018023\n-0.8648814\n1.539517\n4.461643\n0.4076756\n3.734130\n4.380667\n1.8369363\n1.4733574\n1.0154152\n2.0357120\n-0.9465445\n1.9115038\n3.0175037\n1.8736715\n-0.9316645\n2.336868\n0.0550109\n2.4726817\n3.4011771\n3.845458\n\n\nAustralia\nAUS\n3.221980\n-0.0759204\n1.790430\n3.288526\n2.979753\n2.683662\n4.867915\n2.252326\n4.752800\n5.132483\n5.185971\n6.191416\n8.982022\n16.37813\n16.491096\n14.019499\n11.417816\n8.236644\n8.634045\n10.016042\n9.525571\n11.7094683\n10.1579522\n7.8628071\n4.6804357\n6.5472341\n7.0329673\n7.1752729\n9.2337751\n6.0968483\n3.0217266\n1.4788953\n0.8659195\n1.0177842\n2.280091\n2.7174939\n1.2743105\n1.1871334\n0.4793388\n2.560384\n4.6203334\n2.8440646\n2.9679375\n3.237062\n3.824360\n5.1173771\n4.981686\n4.616743\n4.9993050\n1.1578262\n6.2314159\n1.7931684\n-0.1536105\n1.4258044\n-0.5943361\n-0.6051775\n3.7432588\n1.829154\n3.3977230\n1.7397281\n2.8008998\n7.114739\n\n\nAustria\nAUT\n5.087154\n3.3402032\n3.678266\n3.183788\n5.321415\n3.122366\n3.247763\n2.838032\n2.733573\n6.451390\n6.204375\n7.599932\n8.045542\n9.50214\n6.457776\n5.624919\n5.198712\n5.993017\n4.114371\n5.580629\n6.716668\n5.3552894\n3.4727834\n4.9497734\n2.9629958\n2.9509970\n2.4369482\n1.5268554\n2.9647606\n2.9996806\n3.6418715\n3.4790933\n2.7570846\n2.5249426\n1.813918\n0.9862055\n1.2669955\n0.4419052\n0.2563497\n1.364041\n1.9471054\n1.1455957\n1.3075526\n1.739719\n2.537794\n1.8921611\n2.221176\n1.956322\n1.8892642\n0.8730550\n1.8334102\n2.0542357\n1.6238881\n2.1757072\n2.3009787\n1.8482947\n1.0055342\n1.838064\n1.5466716\n2.5586022\n1.9434075\n4.973462\n\n\nAzerbaijan\nAZE\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n83.5495127\n1065.3292302\n747.1245201\n1386.0673977\n545.656352\n26.4191629\n9.2425044\n-0.9651334\n2.1621417\n12.492774\n2.5150102\n4.2143862\n6.9614657\n9.251965\n14.723496\n11.3012191\n21.029329\n27.777459\n-18.8449573\n13.5458168\n22.5243611\n2.8829330\n0.4450645\n-1.2849955\n-8.8496926\n14.6714003\n16.1724003\n12.184877\n-0.2413079\n-7.3959658\n21.5888242\n37.248859\n\n\n\n\n\n\n Download Inflation as xls\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry Name\nCountry Code\n1960\n1961\n1962\n1963\n1964\n1965\n1966\n1967\n1968\n1969\n1970\n1971\n1972\n1973\n1974\n1975\n1976\n1977\n1978\n1979\n1980\n1981\n1982\n1983\n1984\n1985\n1986\n1987\n1988\n1989\n1990\n1991\n1992\n1993\n1994\n1995\n1996\n1997\n1998\n1999\n2000\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n\n\n\n\nAruba\nABW\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n6.08\nNA\nNA\n6.45\nNA\nNA\n7.45\nNA\nNA\n6.92\n6.90\nNA\nNA\nNA\nNA\nNA\n5.710000\nNA\nNA\n10.600000\n8.90\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nAfrica Eastern and Southern\nAFE\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nAfghanistan\nAFG\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n2.490000\nNA\nNA\nNA\n1.69000\nNA\n7.910000\nNA\nNA\n11.180000\nNA\nNA\n11.71\n5.58\nNA\n\n\nAfrica Western and Central\nAFW\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n4.345898\nNA\nNA\n6.971441\nNA\nNA\nNA\nNA\nNA\n\n\nAngola\nAGO\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n14.20\n14.90\n18.90\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n23.64\nNA\nNA\nNA\nNA\n3.780000\n9.430000\n16.77\nNA\nNA\n9.580000\nNA\nNA\nNA\nNA\n16.50\nNA\n15.80\nNA\n\n\nAlbania\nALB\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n5.60\n5.10\n3.60\n4.40\n5.70\n6.70\n6.40\n6.10\n7.00\n7.30\n9.50\n9.10\n26.50\n22.30\n18.40\n12.90\n12.30\n14.90\n17.70\n18.40\n16.80\n16.40\n4.61\n15.00\n14.40\n6.57000\n13.80000\n15.970000\n13.060000\n13.670000\n14.090000\n13.48\n13.38000\n15.87\n18.050000\n17.19\n15.420000\n13.620000\n12.30\n11.47\nNA\nNA\nNA\n\n\nAndorra\nAND\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nArab World\nARB\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n11.17405\n10.26988\n9.613163\n9.867356\n9.467956\n9.210524\nNA\n10.56094\nNA\n10.720961\nNA\n9.629469\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nUnited Arab Emirates\nARE\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1.96\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1.15\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1.80\nNA\nNA\nNA\nNA\n2.25\nNA\nNA\nNA\nNA\n3.12000\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1.640000\n2.460000\n2.24\n2.33\n4.29\n3.11\nNA\n\n\nArgentina\nARG\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n4.8\n6.0\n6.6\n5.60\n3.40\n2.30\n4.50\n2.80\n2.80\n2.00\n2.30\n4.50\n4.73\n4.17\n3.54\n5.30\n4.40\n5.30\n6.00\n7.30\n7.06\n5.44\n6.36\n10.10\n11.76\n18.80\n17.11\n14.82\n12.65\n14.05\n15.00\n17.32\n19.59\n15.36\n13.52\n11.51000\n10.08000\n8.470000\n7.840000\n8.650000\n7.710000\n7.18\n7.22000\n7.10\n7.270000\nNA\nNA\n8.350000\n9.22\n9.84\n11.46\n8.74\nNA\n\n\nArmenia\nARM\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1.80\n5.30\n6.60\n6.70\n9.30\n10.80\n9.40\n11.20\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n9.810000\n22.970000\n18.440000\n19.010000\n18.44\n17.30000\n16.18\n17.500000\n18.26\n17.620000\n17.700000\n13.21\n12.20\n12.18\n10.01\nNA\n\n\nAmerican Samoa\nASM\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n12.99\n17.24\n19.08\n14.87\n13.79\n14.35\n12.41\n12.61\n12.78\n12.96\n13.11\n13.29\n13.38\nNA\nNA\nNA\n5.11\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n5.05\nNA\nNA\nNA\nNA\n9.98000\nNA\nNA\nNA\nNA\n9.200000\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nAntigua and Barbuda\nATG\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n20.46\n19.46\n19.45\n20.69\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n6.00\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n8.42\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nAustralia\nAUS\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n6.26\n6.11\n5.78\n7.16\n9.96\n8.99\n8.26\n8.08\n8.11\n7.23\n6.18\n6.93\n9.59\n10.73\n10.88\n9.72\n8.47\n8.51\n8.37\n7.68\n6.88\n6.29\n6.75\n6.38\n5.93\n5.40\n5.04000\n4.79000\n4.380000\n4.240000\n5.570000\n5.210000\n5.08\n5.23000\n5.66\n6.080000\n6.06\n5.710000\n5.590000\n5.30\n5.16\n6.46\n5.12\n3.7\n\n\nAustria\nAUT\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n2.8\n2.4\n1.5\n1.3\n1.20\n1.30\n2.00\n2.00\n1.80\n2.10\n2.00\n1.90\n2.06\n3.35\n4.11\n3.80\n3.60\n3.12\n3.79\n3.55\n3.14\n3.25\n3.42\n3.59\n4.25\n3.54\n4.35\n5.28\n5.15\n5.52\n4.70\n4.69\n4.01\n4.85\n4.78\n5.97\n5.68000\n5.32000\n4.910000\n4.200000\n5.370000\n4.880000\n4.64\n4.91000\n5.37\n5.670000\n5.80\n6.060000\n5.560000\n4.93\n4.56\n5.20\n6.46\nNA\n\n\n\n\n\n\n Download Unemployment as xls\n\n\n\n\n\n\nAnd we ask you to reproduce all these charts and tables identically:\n\nFrance Phillips CurveTop 15 Inflation MeanEurozone GDP\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncountry\nmean_inf\n\n\n\n\nCongo, Dem. Rep.\n656.8977\n\n\nNicaragua\n475.3175\n\n\nGeorgia\n408.4160\n\n\nAngola\n290.2888\n\n\nBolivia\n241.5436\n\n\nTurkmenistan\n222.3242\n\n\nUkraine\n203.1210\n\n\nBrazil\n203.0250\n\n\nArmenia\n201.2399\n\n\nBelarus\n189.1690\n\n\nPeru\n179.4222\n\n\nArgentina\n160.9128\n\n\nKazakhstan\n152.3263\n\n\nAzerbaijan\n127.4844\n\n\nUzbekistan\n121.4668\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.1.1 Difficulty\n\nThe first obvious difficulty you’re going to encounter is that there are 4 different databases, so you’re going to have to merge them. But on what criteria?\nThere’s a lot of data missing in all directions. We’ll have to make decisions about them: delete them, replace them with averages, medians, forecasts? If you want to display a function without taking into account the NAs, just add na.rm = TRUE in your code.\n\n\n\n4.1.2 Roadmap\nWe’re going to work in stages! And before moving on to merging the data, it’s a good idea to clean up the databases and check that they’re in the right order, one by one. We’ll then merge them in a second stage, retaining all the data. We’ll work in 4 stages:\n\nStep 1: Clean and make tidy the four bases separately\nStep 2: Merge the data\nStep 3: Prepare a dataase for the three tasks\nStep 4: Render graphs and tables"
  },
  {
    "objectID": "dataii.html#create-a-unique-database",
    "href": "dataii.html#create-a-unique-database",
    "title": "4  Data II",
    "section": "4.2 Create a unique Database",
    "text": "4.2 Create a unique Database\n\n4.2.1 Step 1\nStart by creating 4 new objects, df1, df2, df3 and df4 to store the input data.\n\n\n\n\n\n\nSee solution\n\n\n\n\n\n\ndf1 &lt;- GDP\ndf2 &lt;- Inflation\ndf3 &lt;- unempl\ndf4 &lt;- Country\n\n\n\n\nThen work on each base separately:\n\n\n\n\n\n\nWhat should we do?\n\n\n\n\n\nWe just have to make it tidy!\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nSee data I and reproduce the same gather() operation. Be careful with the number of columns!\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndf1 &lt;-gather(df1,year,gdp,3:65)\ndf2 &lt;-gather(df2,year,inflation,3:64)\ndf3 &lt;-gather(df3,year,unemployment,3:65)\n\n\n\n\n\n\n4.2.2 Step 2\n\n\n\n\n\n\nWhat should we do?\n\n\n\n\n\nThe aim is to merge the four bases into a single one. The first step is to merge df1 with df2 and then with df3 and df4 (the only static database). Then keep only the column displayed in the final table. Call the final table df.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nNow it’s crucial to merge the data with a common key. In the three dynamic databases, i.e. those containing information by year, we can no longer use only the country name as a key. All we need to do is add the year to the by = c(\"\") argument of the join function. Be careful with column names!\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndf &lt;- full_join(df1,df2,by=c(\"country\",\"year\"))\n\ncolnames(df3)[1] &lt;- \"country\"\ndf &lt;- full_join(df,df3,by=c(\"country\",\"year\"))\n\ncolnames(df4)[2] &lt;- \"country\"\ndf &lt;- full_join(df,df4,by=c(\"country\"))\n\ndf &lt;- df[,-c(2:2,5:5,7:7,9:11)]\n\nwrite.csv(df, \"DataEco.csv\",row.names = FALSE)\n\n\n\n\nNow, you should be here:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncountry\nyear\ngdp\ninflation\nunemployment\nContinent\nCapital\nCurrency\nLanguages\n\n\n\n\nAruba\n1960\nNA\nNA\nNA\nNorth America\nOranjestad\nAWG\nnl,pa\n\n\nAfrica Eastern and Southern\n1960\n21125015452\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nAfghanistan\n1960\n537777811\nNA\nNA\nAsia\nKabul\nAFN\nps,uz,tk\n\n\nAfrica Western and Central\n1960\n10447637853\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nAngola\n1960\nNA\nNA\nNA\nAfrica\nLuanda\nAOA\npt\n\n\nAlbania\n1960\nNA\nNA\nNA\nEurope\nTirana\nALL\nsq\n\n\nAndorra\n1960\nNA\nNA\nNA\nEurope\nAndorra la Vella\nEUR\nca\n\n\nArab World\n1960\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nUnited Arab Emirates\n1960\nNA\nNA\nNA\nAsia\nAbu Dhabi\nAED\nar\n\n\nArgentina\n1960\nNA\nNA\nNA\nSouth America\nBuenos Aires\nARS\nes,gn\n\n\nArmenia\n1960\nNA\nNA\nNA\nAsia\nYerevan\nAMD\nhy,ru\n\n\nAmerican Samoa\n1960\nNA\nNA\nNA\nOceania\nPago Pago\nUSD\nen,sm\n\n\nAntigua and Barbuda\n1960\nNA\nNA\nNA\nNorth America\nSaint John’s\nXCD\nen\n\n\nAustralia\n1960\n18606562979\nNA\nNA\nOceania\nCanberra\nAUD\nen\n\n\nAustria\n1960\n6592693841\nNA\nNA\nEurope\nVienna\nEUR\nde"
  },
  {
    "objectID": "dataii.html#france-phillips-curve-1",
    "href": "dataii.html#france-phillips-curve-1",
    "title": "4  Data II",
    "section": "4.3 France Phillips Curve",
    "text": "4.3 France Phillips Curve\n\n\n\n\n\n\nWhat should we do?\n\n\n\n\n\nWe need to create a graph with the unemployment rate on the x-axis and the inflation rate on the y-axis. The data must be filtered beforehand, so as to keep only France for the years in which there are no missing data.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nUse de filter() function in tidyverse to select only France data. Then use again filter() to keep only available data on inflation and unemployment. The command !is.na() will help you to erase missing data. For the graph, you can try the ggplot package with:\n\nggplot(France, aes(x = , y = )) +\n  geom_point(aes(color = factor())) +\n  stat_smooth(method = \"lm\",\n              col = \"#C42126\", se = FALSE, size = 1\n  ) \n\nThe method=\"lm\" command will show the linear regression.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nFrance &lt;- filter(DataEco,country==\"France\")\n\nFrance &lt;- filter(France, !is.na(inflation))\nFrance &lt;- filter(France, !is.na(unemployment))\n\nggplot(France, aes(x = unemployment, y = inflation)) +\n  geom_point(aes(color = factor(year))) +\n  stat_smooth(method = \"lm\",\n              col = \"#C42126\", se = FALSE, size = 1\n  )"
  },
  {
    "objectID": "dataii.html#top-15-inflation-mean-1",
    "href": "dataii.html#top-15-inflation-mean-1",
    "title": "4  Data II",
    "section": "4.4 Top 15 Inflation Mean",
    "text": "4.4 Top 15 Inflation Mean\n\n\n\n\n\n\nWhat should we do?\n\n\n\n\n\nThe aim is to create a ranking of data by country, based on the average inflation rate over all the years observed, and then to retain only the top 15 values.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou’ll have to use the %&gt;% pipe function! Take another look at the “Learning by Doing” section of Data I, where the groupe_by(), summarize(), top_n() and arrange() functions are used.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ninf_mean &lt;- DataEco %&gt;% group_by(country) %&gt;% summarise(mean_inf = mean(inflation,na.rm = TRUE))\ninf_mean &lt;- inf_mean %&gt;% top_n(15, mean_inf) %&gt;% arrange(desc(mean_inf))"
  },
  {
    "objectID": "dataii.html#eurozone-gdp-1",
    "href": "dataii.html#eurozone-gdp-1",
    "title": "4  Data II",
    "section": "4.5 Eurozone GDP",
    "text": "4.5 Eurozone GDP\n\n\n\n\n\n\nWhat should we do?\n\n\n\n\n\nThe aim is to create a dynamic graph of the sum of Euro zone countries GDP.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nYou’ll have to use the dygraph package. First, filter the data by keeping only countries that have euro as a currency, and keep only years after 2000. Then, create a base with 2 columns, “year” and “GDP”, which is the sum of all countries gdp and call the base gdp_eur. finally, run dygraph(gdp_eur).\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ngdp_eur &lt;- DataEco %&gt;% filter(Currency==\"EUR\", year &gt; 2000)\ngdp_eur &lt;- gdp_eur %&gt;% group_by(year) %&gt;% summarise(GDP = sum(gdp,na.rm = TRUE))\n\ngdp_eur$GDP &lt;- gdp_eur$GDP/1000000000\n\nlibrary(dygraphs)\n\ndygraph(gdp_eur)"
  },
  {
    "objectID": "loops.html#factorial",
    "href": "loops.html#factorial",
    "title": "5  Loops & Functions",
    "section": "5.1 Factorial",
    "text": "5.1 Factorial\nBut let’s start with a simple example. We’re going to create a function \\(Fac\\) that returns the factorial value of an integer:\n\\[Fac(n) = n! = n \\times (n-1) \\times (n-2) \\times ... \\times2 \\times 1 \\]\nA perfect example of a loop! In fact, to calculate factorial \\(n\\), you must first calculate factorial \\(n-1\\), which implies calculating factorial \\(n-2\\) and so on. And therefore work in stages, exactly \\(n\\) stages. We’ll create an index i, which will move between 1 and n and carry out the n tasks we’ve assigned to it.\nIn almost all computer languages, the loop will always begin with for (i in 1:n) and then followed by the statement. In R we have :\nfor (value in sequence){ statement }\n\nFac &lt;- function(n){\n  x &lt;- 1\n  for (i in 1:n) {\n    x &lt;- x*i\n    }\n  return(x)\n}\nFac(10)\n\nExercise 1: copy paste the last code and find \\(Fac(20)\\). Try witht others numbers but be careful, not too high!"
  },
  {
    "objectID": "loops.html#the-value-of-e",
    "href": "loops.html#the-value-of-e",
    "title": "5  Loops & Functions",
    "section": "5.2 The value of e",
    "text": "5.2 The value of e\nOnce the factorial function has been created, we can determine an approximate value for \\(e\\) using the following formula:\n\\[ e = \\sum_{n=0}^{+ \\infty} \\frac{1}{n!} \\] Or, in an IT point of view:\n\\[ e = \\lim\\limits_{N \\rightarrow +\\infty} \\sum_{n=0}^{N} \\frac{1}{n!} \\] This will enable us to calculate an approximate value as N becomes larger. Exercise 2: create a function that take \\(N\\) as input and return an approximated value of \\(e\\).\n\n    ExpT &lt;- function(n){\n      x = vector()\n      for (i in 1:n){\n    x[i] = 1/Fac(i)\n    y = 1 + sum(x[1:i])\n      }\n      return(y)\n    }\n\n    e &lt;- ExpT(10)\n    e"
  },
  {
    "objectID": "loops.html#the-fibonnacci-suite",
    "href": "loops.html#the-fibonnacci-suite",
    "title": "5  Loops & Functions",
    "section": "5.3 The Fibonnacci suite",
    "text": "5.3 The Fibonnacci suite\nA classic loop! For those of you born on another planet, the fibonnacci sequence is ubiquitous on our earth. Fibonacci numbers often appear in nature when logarithmic spirals are constructed from a discrete unit, such as in sunflowers or pine cones. The number of petals in the Marguerite (and other compound flowers such as the sunflower) belongs to the Fibonacci sequence: often 34, 55 or 89. This is explained by the plant’s development mechanism.\nThe Fibonacci sequence is the sequence defined by its first two terms \\(F_0=F_1=1\\) and by the following recurrence relation:\n\\[  \\forall n \\in \\mathbb{N}, F_{n+2}=F_{n+1} + F_n \\]\n\nCould you create a function Fibo(n) that takes \\(n\\) as an input an return the value of the fibonnaci suite?\n\n\n    Fibo &lt;- function(n){\n      Fibo = vector()\n      Fibo[1] = 1\n      Fibo[2] = 1\n      for (i in 3:n){\n    Fibo[i] = Fibo[i-1] + Fibo[i-2]\n      }\n      return(Fibo)\n    }\n    Fibo(15)\n    Fib &lt;- Fibo(15)\n    Fib[15]\n\n\nBy the way, what about the Golden ratio?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nThe Golden ratio is the limit of the ratio of 2 consecutive fibonnacci numbers :\n\\[\\phi = \\lim\\limits_{n \\rightarrow +\\infty}  \\frac{F_{n+1}}{F_n}\\]"
  },
  {
    "objectID": "loops.html#learning-by-doing",
    "href": "loops.html#learning-by-doing",
    "title": "5  Loops & Functions",
    "section": "5.4 Learning by doing",
    "text": "5.4 Learning by doing\nCan you calculate the \\(\\Delta\\) for any second-degree polynomial? \\[\\Delta = b^2 -4ac  \\]\n\n\n\n\n\n\nSee solution\n\n\n\n\n\n\nDelta &lt;- function(a,b,c){\n  x &lt;- b^2 - 4*a*c\n  return(x)\n}\n\nDelta(1,2,-3)\n\n\n\n\nUse the following results to find an approximate value of \\(\\pi\\) :\n\\[\\frac{\\pi^2}{6} = \\lim\\limits_{n \\rightarrow +\\infty} \\sum_{i=1}^{n} \\frac{1}{i^2}  \\]\n\n\n\n\n\n\nSee solution\n\n\n\n\n\n\npi &lt;- function(n){\n  x = vector()\n  for (i in 1:n){\n    x[i] = 1/i^2\n    y =sum(x[1:i])\n  }\n  \n  print(y)\n  w = sqrt(6*y)\n  print(w)\n}"
  },
  {
    "objectID": "loops.html#exercices",
    "href": "loops.html#exercices",
    "title": "5  Loops & Functions",
    "section": "5.5 Exercices",
    "text": "5.5 Exercices\n\nUsing a loop, display the squares of the numbers from 1 to 10 (use print() to see the results). \nWhat loops are used to loop until a specific condition is met? whileforelififelse\nI want to perform a vectorization calculation on a list of objects. I use: applymapplytapplylapply\nCreate a “Func” function that gives the cube root of a number “x”. \nI didn’t think I’d spend so much time screwing up.. TRUEFALSE"
  },
  {
    "objectID": "statistics.html#simulate-a-sample-of-data",
    "href": "statistics.html#simulate-a-sample-of-data",
    "title": "6  Statistics",
    "section": "6.1 Simulate a sample of data",
    "text": "6.1 Simulate a sample of data\nThe first question to ask when simulating random variables is: do we want to keep the same data every time? It may sound silly, but it’s absolutely crucial, especially if you’re going to be sharing your work with other people.\nIn fact, when you generate random numbers in R, you are actually generating pseudorandom numbers. These numbers are generated with an algorithm that requires a seed to initialize. Being pseudorandom instead of pure random means that, if you know the seed and the generator, you can predict (and reproduce) the output. The set.seed() function in R is used to create reproducible results when writing code that involves creating variables that take on random values. By using the set.seed() function, you guarantee that the same random values are produced each time you run the code.\n\nset.seed(0)\n\n\nLet’s begin our journey into the wonderful world of R statistics with the simplest example. Suppose you want to create a vector of \\[ i \\in [1; 10000]\\] observations with a uniform distribution between 1 and 10 : \\[ X_i \\sim U_{[1;10]}\\]\nNothing simplier as runif() :\n\ndata &lt;- runif(n=10000, min=1, max=10)\n#create histogram to visualize distribution \nhist(data, col='steelblue', main='Histogram of Runif')\n\n\n\n\nIt seems to work. The following figure shows the simulation of a draw of 1000 observations of a random variable following different distributions:\n\nNormalPoissonBinomialBetaExponential\\(\\chi^2\\)"
  },
  {
    "objectID": "statistics.html#tests",
    "href": "statistics.html#tests",
    "title": "6  Statistics",
    "section": "6.2 Tests",
    "text": "6.2 Tests\n\n6.2.1 \\(\\chi^2\\)\nR offers a multitude of statistical tests to validate or invalidate an \\(H_0\\) hypothesis. Here, we’ll perform a chi-square test to determine whether a sample is likely to follow a given probability distribution.\nSuppose we want to know whether a 6-sided die is rigged. To do this, we roll it 6,000 times and observe the results in a “tie” vector. The following code then executes a \\(\\chi^2\\) adequacy test:\n\n# Observed Value\n\ndie &lt;- c(956,1032,1050,963,999,1000)\n\n# theoretical probabilities: from a theoretical point of view,\n# we should have 1/6 for each face of the die.\n\nproba &lt;- c(1/6,1/6,1/6,1/6,1/6,1/6)\n\n# Chi square test\n\nchisq.test(die,p=proba)\n\n\n    Chi-squared test for given probabilities\n\ndata:  die\nX-squared = 6.83, df = 5, p-value = 0.2336\n\n\nThus, the \\(T\\) statistic follows the \\(\\chi^2\\) distribution with five degrees of freedom. This \\(\\chi^2\\) distribution gives the value below which the draw is considered compliant with a risk \\(\\alpha = 0.05: P(T &lt; 11.07) = 0.95\\). Since \\(6.83 &lt; 11.07\\), the null hypothesis cannot be rejected: this statistical data does not allow us to consider that the die is rigged.\n\n\n6.2.2 t-test\n\nx &lt;- rnorm(1000, mean = 0, sd = 0.5)\nt.test(x, mu=10) # testing if mean of x could be equal to 10\n\n\n    One Sample t-test\n\ndata:  x\nt = -624.55, df = 999, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 10\n95 percent confidence interval:\n -0.01711833  0.04563231\nsample estimates:\n mean of x \n0.01425699 \n\n\nR gives direct results. Here, we have simulated a random sample with a normal distribution \\(N(0,0.5)\\) and wanted to know if the mean was 10. The result of the t-test is clear: we reject the null hypothesis at 99% and R proposes an alternative and a confidence interval.\n\nYou can find here a list of many other test include in R!"
  },
  {
    "objectID": "statistics.html#the-central-limit-theorem",
    "href": "statistics.html#the-central-limit-theorem",
    "title": "6  Statistics",
    "section": "6.3 The Central Limit Theorem",
    "text": "6.3 The Central Limit Theorem\nPerhaps the most beautiful, the most mysterious, the most fascinating, the most wonderful of all mathematical theorems! The central limit theorem (CLT) establishes that, in many situations, for identically distributed independent samples, the standardized sample mean tends towards the standard normal distribution even if the original variables themselves are not normally distributed.\nMore concretely, this means that any random variable, whatever its distribution, will see the distribution of its mean tend towards a normal distribution when the sample becomes very large.\n\\[ \\sqrt n (\\bar X_n-\\mu) \\rightarrow \\mathcal N (0,\\sigma^2)   \\] What does this have to do with programming in R? Well, we’re going to try to test the CLT, by creating a sample value of the mean of a distribution, and as we increase the size of this sample, the CLT tells us that we should observe a normal distribution. The following code works like this:\n\nCreate a column sample5 with empty value\nTake 10,000 random samples of size n=100 from the uniform law simulated above\nTake the mean of each 10,000 sample of size 100\nCompute the mean and standard deviation of sample5\nCreate histogram to visualize sampling distribution of sample means\n\n\nsample5 &lt;- c()\n\n#take 10,000 random samples of size n=100\nn = 10000\nfor (i in 1:n){\n  sample5[i] = mean(sample(data, 100, replace=TRUE))\n}\n\n#calculate mean and standard deviation of sample means\nmean(sample5)\n\n[1] 5.502855\n\nsd(sample5)\n\n[1] 0.2630924\n\n#create histogram to visualize sampling distribution of sample means\nhist(sample5, col ='steelblue', xlab='Distribution', main='Sample size = 100')\n\n\n\n\nWhat do you think? It looks like a beautiful Galton board:\n\n\n\n\nThe Galton Board"
  },
  {
    "objectID": "statistics.html#learning-by-doing",
    "href": "statistics.html#learning-by-doing",
    "title": "6  Statistics",
    "section": "6.4 Learning by doing",
    "text": "6.4 Learning by doing\n\nRun a sample of 10,000 observation of an uniform law, a normal law and a Poisson law\nCreate a sequence of 10,000 numbers in a column and bind the three samples of the laws.\nCreate a function that compute the mean and the standard deviation.\nIs the law of large number respected here?\n\n\n\n\n\n\n\nSee solution\n\n\n\n\n\n\n# Create 10000 random sample\nl_uniforme &lt;- runif(10000)    # 10000 values on uniform law\nl_normale  &lt;- rnorm(10000, mean = 1)   # Normal law\nl_poisson  &lt;- rpois(10000, lambda = 1) # Poisson Law\nID &lt;- seq(1,10000)\n# Combine\n\nall &lt;- cbind(ID,l_uniforme,l_normale,l_poisson)\n\nall &lt;- as.data.frame(all)\n\n\n\n# Apply\nmoyenne    &lt;- apply(all,2,mean)\necart_type &lt;- apply(all,2,sd)\n\n# combine lignes\nall &lt;- rbind(moyenne,ecart_type)\nall &lt;- round(all, digits = 1)     # arrondi\nall\n\n               ID l_uniforme l_normale l_poisson\nmoyenne    5000.5        0.5         1         1\necart_type 2886.9        0.3         1         1"
  },
  {
    "objectID": "statistics.html#exercices",
    "href": "statistics.html#exercices",
    "title": "6  Statistics",
    "section": "6.5 Exercices",
    "text": "6.5 Exercices\n\nHow do you get a sample of size 250 of a Poisson distribution withe mean=3? \nWhat test can be used to judge the fit between a series of statistical data and a probability distribution defined a priori? t-testF-testchi-squaredKolmogorov\nI want to test whether the variance of my sample is equal to 1. To do this, I use : t-testF-testCorrelationGoodness of Fit\nCreate a sample of 10,000 observations of a normal distribution with mean 10 and variance 20 called “Norm”. \nMaking statistics with R is amazing! TRUEFALSE"
  },
  {
    "objectID": "econometrics1.html#the-wooldridge-package",
    "href": "econometrics1.html#the-wooldridge-package",
    "title": "7  Econometrics",
    "section": "7.1 The Wooldridge package",
    "text": "7.1 The Wooldridge package\nWhat better tool than R for econometrics? It’s in its very DNA: R was originally a statistical software specifically designed for all kinds of econometric analysis. In this first chapter devoted to econometrics, we’re going to use a very useful package based on one of the greatest references in econometrics: Introductory Econometrics: a modern approach by Wooldridge (2015).\nBased on this book, some R users have done us a great service and published an extremely useful package that we will use in these two sessions: package(wooldridge). You will find all the explanations on the different databases included, variable names, nature, regression example etc… here: Wooldridge package\nThis package contains 115 databases used in the book. You can then easily reproduce the book’s regressions using the same data as Wooldridge. Very practical for learning econometrics! A simple command displays them all:\n\nlibrary(wooldridge)\nls(\"package:wooldridge\")\n\n  [1] \"admnrev\"       \"affairs\"       \"airfare\"       \"alcohol\"      \n  [5] \"apple\"         \"approval\"      \"athlet1\"       \"athlet2\"      \n  [9] \"attend\"        \"audit\"         \"barium\"        \"beauty\"       \n [13] \"benefits\"      \"beveridge\"     \"big9salary\"    \"bwght\"        \n [17] \"bwght2\"        \"campus\"        \"card\"          \"catholic\"     \n [21] \"cement\"        \"census2000\"    \"ceosal1\"       \"ceosal2\"      \n [25] \"charity\"       \"consump\"       \"corn\"          \"countymurders\"\n [29] \"cps78_85\"      \"cps91\"         \"crime1\"        \"crime2\"       \n [33] \"crime3\"        \"crime4\"        \"discrim\"       \"driving\"      \n [37] \"earns\"         \"econmath\"      \"elem94_95\"     \"engin\"        \n [41] \"expendshares\"  \"ezanders\"      \"ezunem\"        \"fair\"         \n [45] \"fertil1\"       \"fertil2\"       \"fertil3\"       \"fish\"         \n [49] \"fringe\"        \"gpa1\"          \"gpa2\"          \"gpa3\"         \n [53] \"happiness\"     \"hprice1\"       \"hprice2\"       \"hprice3\"      \n [57] \"hseinv\"        \"htv\"           \"infmrt\"        \"injury\"       \n [61] \"intdef\"        \"intqrt\"        \"inven\"         \"jtrain\"       \n [65] \"jtrain2\"       \"jtrain3\"       \"jtrain98\"      \"k401k\"        \n [69] \"k401ksubs\"     \"kielmc\"        \"labsup\"        \"lawsch85\"     \n [73] \"loanapp\"       \"lowbrth\"       \"mathpnl\"       \"meap00_01\"    \n [77] \"meap01\"        \"meap93\"        \"meapsingle\"    \"minwage\"      \n [81] \"mlb1\"          \"mroz\"          \"murder\"        \"nbasal\"       \n [85] \"ncaa_rpi\"      \"nyse\"          \"okun\"          \"openness\"     \n [89] \"pension\"       \"phillips\"      \"pntsprd\"       \"prison\"       \n [93] \"prminwge\"      \"rdchem\"        \"rdtelec\"       \"recid\"        \n [97] \"rental\"        \"return\"        \"saving\"        \"school93_98\"  \n[101] \"sleep75\"       \"slp75_81\"      \"smoke\"         \"traffic1\"     \n[105] \"traffic2\"      \"twoyear\"       \"volat\"         \"vote1\"        \n[109] \"vote2\"         \"voucher\"       \"wage1\"         \"wage2\"        \n[113] \"wagepan\"       \"wageprc\"       \"wine\"         \n\n\nLet’s have a look on the wage1 database, these are data from the 1976 Current Population Survey, collected by Henry Farber when he and wooldridge were colleagues at MIT in 1988 :\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nwage\neduc\nexper\ntenure\nnonwhite\nfemale\nmarried\nnumdep\nsmsa\nnorthcen\nsouth\nwest\nconstruc\nndurman\ntrcommpu\ntrade\nservices\nprofserv\nprofocc\nclerocc\nservocc\nlwage\nexpersq\ntenursq\n\n\n\n\n3.100000\n11\n2\n0\n0\n1\n0\n2\n1\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1.131402\n4\n0\n\n\n3.240000\n12\n22\n2\n0\n1\n1\n3\n1\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n1\n1.175573\n484\n4\n\n\n3.000000\n11\n2\n0\n0\n0\n0\n2\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1.098612\n4\n0\n\n\n6.000000\n8\n44\n28\n0\n0\n1\n0\n1\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1.791759\n1936\n784\n\n\n5.300000\n12\n7\n2\n0\n0\n1\n1\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1.667707\n49\n4\n\n\n8.750000\n16\n9\n8\n0\n0\n1\n0\n1\n0\n0\n1\n0\n0\n0\n0\n0\n1\n1\n0\n0\n2.169054\n81\n64\n\n\n11.250000\n18\n15\n7\n0\n0\n0\n0\n1\n0\n0\n1\n0\n0\n0\n1\n0\n0\n1\n0\n0\n2.420368\n225\n49\n\n\n5.000000\n12\n5\n3\n0\n1\n0\n0\n1\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n1.609438\n25\n9\n\n\n3.600000\n12\n26\n4\n0\n1\n0\n2\n1\n0\n0\n1\n0\n0\n0\n1\n0\n0\n1\n0\n0\n1.280934\n676\n16\n\n\n18.180000\n17\n22\n21\n0\n0\n1\n0\n1\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n2.900322\n484\n441\n\n\n6.250000\n16\n8\n2\n0\n1\n0\n0\n1\n0\n0\n1\n0\n0\n0\n1\n0\n0\n1\n0\n0\n1.832582\n64\n4\n\n\n8.130000\n13\n3\n0\n0\n1\n0\n0\n1\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n1\n0\n2.095561\n9\n0\n\n\n8.770001\n12\n15\n0\n0\n0\n1\n2\n1\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n2.171337\n225\n0\n\n\n5.500000\n12\n18\n3\n0\n0\n0\n0\n1\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1.704748\n324\n9\n\n\n22.200001\n12\n31\n15\n0\n0\n1\n1\n1\n0\n0\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n3.100092\n961\n225\n\n\n\n\n\nNow we are ready for our first regression!"
  },
  {
    "objectID": "econometrics1.html#single-regression",
    "href": "econometrics1.html#single-regression",
    "title": "7  Econometrics",
    "section": "7.2 Single regression",
    "text": "7.2 Single regression\nWe want to estimate the parameter of the following regression:\n\\[ lwage_i = \\beta_0 + \\beta_1 educ_i + \\epsilon_i   \\] With:\n\nlwage: the log wage\neduc: the level of education in years\n\n\n\n\n\n\n\nImportant\n\n\n\n\n\\(Y = \\beta_0+\\beta_1 X\\): \\(X\\) increases by one unit, \\(Y\\) increases by \\(\\beta_1\\) units.\n\\(\\log(Y) = \\beta_0+\\beta_1 X\\): \\(X\\) increases by one unit, \\(Y\\) increases by \\(\\beta_1 \\%\\) units.\n\\(\\log(Y) = \\beta_0+\\beta_1 \\log(X)\\): \\(X\\) increases by \\(1 \\%\\) unit, \\(Y\\) increases by \\(\\beta_1 \\%\\) units.\n\n\n\nThe easiest way to do so is:\n\nlog_wage_model &lt;- lm(lwage ~ educ, data = wage1)\nsummary(log_wage_model)\n\n\nCall:\nlm(formula = lwage ~ educ, data = wage1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.21158 -0.36393 -0.07263  0.29712  1.52339 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.583773   0.097336   5.998 3.74e-09 ***\neduc        0.082744   0.007567  10.935  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4801 on 524 degrees of freedom\nMultiple R-squared:  0.1858,    Adjusted R-squared:  0.1843 \nF-statistic: 119.6 on 1 and 524 DF,  p-value: &lt; 2.2e-16\n\n\nThe \\(educ\\) variable is therefore over 95% significant, and the addition of an extra year of study increases the average salary by 8.27%.\nWith two variables, it is possible to plot it:\n\nplot(lwage ~ educ, data = wage1)\nabline(log_wage_model)\n\n\n\n\nAs you can see above, R’s summary command is not very ergonomic for reading results… That’s why a few econometrics geeks decided to create the stargazer package, which makes it possible to display regression results in a clearer and more attractive way:\n\nlibrary(stargazer)\nstargazer(log_wage_model, type = \"text\", single.row = TRUE, header = FALSE)\n\n\n===============================================\n                        Dependent variable:    \n                    ---------------------------\n                               lwage           \n-----------------------------------------------\neduc                     0.083*** (0.008)      \nConstant                 0.584*** (0.097)      \n-----------------------------------------------\nObservations                    526            \nR2                             0.186           \nAdjusted R2                    0.184           \nResidual Std. Error      0.480 (df = 524)      \nF Statistic          119.582*** (df = 1; 524)  \n===============================================\nNote:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nYou can even have the table directly in Latex format if you don’t specify the type. Very practical for papers!\n\nlibrary(stargazer)\nstargazer(log_wage_model, single.row = TRUE, header = FALSE)\n\n\n\\begin{table}[!htbp] \\centering \n  \\caption{} \n  \\label{} \n\\begin{tabular}{@{\\extracolsep{5pt}}lc} \n\\\\[-1.8ex]\\hline \n\\hline \\\\[-1.8ex] \n & \\multicolumn{1}{c}{\\textit{Dependent variable:}} \\\\ \n\\cline{2-2} \n\\\\[-1.8ex] & lwage \\\\ \n\\hline \\\\[-1.8ex] \n educ & 0.083$^{***}$ (0.008) \\\\ \n  Constant & 0.584$^{***}$ (0.097) \\\\ \n \\hline \\\\[-1.8ex] \nObservations & 526 \\\\ \nR$^{2}$ & 0.186 \\\\ \nAdjusted R$^{2}$ & 0.184 \\\\ \nResidual Std. Error & 0.480 (df = 524) \\\\ \nF Statistic & 119.582$^{***}$ (df = 1; 524) \\\\ \n\\hline \n\\hline \\\\[-1.8ex] \n\\textit{Note:}  & \\multicolumn{1}{r}{$^{*}$p$&lt;$0.1; $^{**}$p$&lt;$0.05; $^{***}$p$&lt;$0.01} \\\\ \n\\end{tabular} \n\\end{table}"
  },
  {
    "objectID": "econometrics1.html#multiple-regression",
    "href": "econometrics1.html#multiple-regression",
    "title": "7  Econometrics",
    "section": "7.3 Multiple regression",
    "text": "7.3 Multiple regression\n\n7.3.1 Wage\nWhat if we want a multiple regression? Nothing easier: just add the name of the variable you need to. For instance, for\n\\[ lwage_i = \\beta_0 + \\beta_1 educ_i + \\beta_2 exper + \\beta_3 tenure + \\epsilon_i   \\] With:\n\nlwage: the log wage\neduc: the level of education in years\nexper: the number of year’s experience in working\ntenure: the number of years in the firm\n\n\nlog_wage_model2 &lt;- lm(lwage ~ educ + exper + tenure, data = wage1)\nstargazer(log_wage_model2, type = \"text\", single.row = TRUE, header = FALSE)\n\n\n===============================================\n                        Dependent variable:    \n                    ---------------------------\n                               lwage           \n-----------------------------------------------\neduc                     0.092*** (0.007)      \nexper                     0.004** (0.002)      \ntenure                   0.022*** (0.003)      \nConstant                 0.284*** (0.104)      \n-----------------------------------------------\nObservations                    526            \nR2                             0.316           \nAdjusted R2                    0.312           \nResidual Std. Error      0.441 (df = 522)      \nF Statistic           80.391*** (df = 3; 522)  \n===============================================\nNote:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n\n\n7.3.2 Effects of Pollution on Housing Prices\nWe will now study the effect of pollution on the price of a house using two models. In the first, we want to run the following regression:\n\\[  \\log(price) = \\beta_0 + \\beta_1\\log(nox) + \\beta_2\\log(dist)  +\\beta_3rooms  + \\beta_4stratio + \\epsilon \\]\nWhere\n\nprice: the price of the house\nnox: Nitrous Oxide concentration; parts per million.\ndist: weighted distance of the community to 5 employment centers.\nrooms: the number of rooms\nstratio: average student-teacher ratio of schools in the community.\n\nThe second model will perform:\n\\[  \\log(price) = \\beta_0 + \\beta_1\\log(nox) + \\beta_2\\log(dist)  +\\beta_3rooms + \\beta_4 rooms^2  + \\beta_5stratio + \\epsilon \\]\n\nprice &lt;- lm(lprice ~ lnox + log(dist) + rooms + stratio, data = hprice2)\nprice2 &lt;- lm(lprice ~ lnox + log(dist) + rooms+I(rooms^2) + stratio, data = hprice2)\nstargazer(price, price2, type = \"text\", single.row = TRUE, header = FALSE)\n\n\n=====================================================================\n                                   Dependent variable:               \n                    -------------------------------------------------\n                                         lprice                      \n                              (1)                      (2)           \n---------------------------------------------------------------------\nlnox                   -0.954*** (0.117)        -0.902*** (0.115)    \nlog(dist)              -0.134*** (0.043)         -0.087** (0.043)    \nrooms                   0.255*** (0.019)        -0.545*** (0.165)    \nI(rooms2)                                        0.062*** (0.013)    \nstratio                -0.052*** (0.006)        -0.048*** (0.006)    \nConstant               11.084*** (0.318)        13.385*** (0.566)    \n---------------------------------------------------------------------\nObservations                  506                      506           \nR2                           0.584                    0.603          \nAdjusted R2                  0.581                    0.599          \nResidual Std. Error     0.265 (df = 501)         0.259 (df = 500)    \nF Statistic         175.855*** (df = 4; 501) 151.770*** (df = 5; 500)\n=====================================================================\nNote:                                     *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nIn the first model (i.e. without taking into account the \\(rooms^2\\) effect), we can see that adding an additional part increases the price by around 25.5%. This is very different from model 2, where the effect is 25.5% for a value of \\(rooms\\)=6.45, but changes rapidly when \\(rooms\\) increases or decreases.\nThis is because, from a certain point onwards, the effect becomes positive and the quadratic shape means that the semi-elasticity of \\(price\\) with respect to \\(rooms\\) increases as \\(rooms\\) increases."
  },
  {
    "objectID": "econometrics1.html#learning-by-doing",
    "href": "econometrics1.html#learning-by-doing",
    "title": "7  Econometrics",
    "section": "7.4 Learning by doing",
    "text": "7.4 Learning by doing\nAnother very useful tool to learn econometrics is provided by the Wooldridge Vignette made by Justin M Shea. It aims to present 18 econometrics Technics for many different situations, including time series.\nFor the 3 studies below, run the code and try to understand which techniques are used.\n\n# 1: the ivreg function\nwage_educ_model &lt;- lm(lwage ~ educ, data = mroz)\nfatheduc_model &lt;- lm(educ ~ fatheduc, data = mroz, subset = (inlf==1))\nlibrary(\"AER\") # g the ivreg function in the AER (Applied Econometrics with R) package.\nwage_educ_IV &lt;- ivreg(lwage ~ educ | fatheduc, data = mroz)\nstargazer(wage_educ_model, fatheduc_model, wage_educ_IV, type = \"text\", single.row = TRUE,\nheader = FALSE)\n\n# 2: Wages and productivity\nwage_time &lt;- lm(lhrwage ~ loutphr + t, data = earns)\nwage_diff &lt;- lm(diff(lhrwage) ~ diff(loutphr), data = earns)\nstargazer(wage_time, wage_diff, type = \"text\", single.row = TRUE, header = FALSE)\n\n# 3: Number of arrest\nformula &lt;- (narr86 ~ pcnv + avgsen + tottime + ptime86 + qemp86 + inc86 + black +\nhispan + born60)\necon_crime_model &lt;- lm(formula, data = crime1)\necon_crim_poisson &lt;- glm(formula, data = crime1, family = poisson)\nstargazer(econ_crime_model, econ_crim_poisson, type = \"text\", single.row = TRUE, header = FALSE)\n\n\n\n\n\n\n\nSee solution\n\n\n\n\n\nHave a look on the Vignette!"
  },
  {
    "objectID": "econometrics1.html#exercices",
    "href": "econometrics1.html#exercices",
    "title": "7  Econometrics",
    "section": "7.5 Exercices",
    "text": "7.5 Exercices\n\nWrite the following regression based on data=hprice2: \\[\\log(price) = \\beta_0 + \\beta_1\\log(nox) +  \\beta_2\\log(crime) + \\epsilon \\] \nWhich of the two house price models would you choose and why? Model 1: the F Statistic is biggerModel 2: the F Statistic is lowerModel 2: the R square is biggerModel 1: the constant is lower\nI want to standardize my data for a regression. I use the function : normalize()norm()standard()scale()\nUsing the ivreg() function and the wage2 database, perform the IV model with \\(lwage = \\beta_0 + \\beta_1 educ\\) and \\(educ = \\beta_0 + \\beta_1 sibs\\). \nI’ll never again use any software other than R to do econometrics! TRUEFALSE\n\n\n\n\n\nWooldridge, Jeffrey M. 2015. Introductory Econometrics: A Modern Approach. Cengage learning."
  },
  {
    "objectID": "ML.html#different-types-of-algorithm",
    "href": "ML.html#different-types-of-algorithm",
    "title": "8  Machine Learning",
    "section": "8.1 Different types of algorithm",
    "text": "8.1 Different types of algorithm\nMachine learning encompasses a wide range of algorithms, and they can be broadly classified into two main categories: Supervised Learning and Unsupervised Learning.\n\n8.1.1 Supervised Learning\nIn supervised learning, the algorithm is provided with labeled training data, where the input data is paired with the correct output. The goal is to learn a mapping from the input to the output based on this labeled training data. Here are some common supervised learning algorithms:\n\nLinear Regression\n\nLinear regression is used for regression tasks, where the goal is to predict a continuous numerical value. It fits a linear equation to the data and is widely used in various fields for tasks like predicting house prices or stock prices.\n\nLogistic Regression\n\nLogistic regression is a binary classification algorithm used to predict one of two classes, often represented as 0 and 1. It models the probability of an input belonging to a particular class.\n\nDecision Trees\n\nDecision trees are versatile for both regression and classification tasks. They create a tree-like structure to make decisions by branching based on the features of the data.\n\nRandom Forest\n\nRandom forests are an ensemble method that combines multiple decision trees to improve accuracy and reduce overfitting. They are widely used in classification and regression problems.\n\nSupport Vector Machines (SVM)\n\nSVM is a powerful algorithm used for classification tasks. It finds a hyperplane that best separates different classes of data.\n\n\n8.1.2 Unsupervised Learning\nIn unsupervised learning, the algorithm is not provided with labeled data, and it’s tasked with finding hidden patterns or structures in the data. Here are some common unsupervised learning algorithms:\n\nK-Means Clustering\n\nK-Means clustering is used for data segmentation and grouping. It aims to partition data points into K clusters based on their similarity.\n\nHierarchical Clustering\n\nHierarchical clustering creates a hierarchy of clusters by successively merging or splitting clusters. It’s useful for understanding the structure of the data.\n\nPrincipal Component Analysis (PCA)\n\nPCA is a dimensionality reduction technique used to transform high-dimensional data into a lower-dimensional space while preserving the most significant information.\n\nAssociation Rule Learning (Apriori)\n\nApriori is used for discovering interesting relations between variables in large databases. It’s often used in market basket analysis to identify itemset associations.\n\nSelf-Organizing Maps (SOM)\n\nSOM is a type of artificial neural network used for unsupervised learning and data visualization. It maps high-dimensional data onto a lower-dimensional grid.\n\n\n\n\n\n\n\n\n\n\nThese are just a few examples of machine learning algorithms, and the field continues to evolve with new algorithms and techniques being developed regularly. The choice of algorithm depends on the specific task and the characteristics of the data you are working with."
  },
  {
    "objectID": "ML.html#a-glm-prediction",
    "href": "ML.html#a-glm-prediction",
    "title": "8  Machine Learning",
    "section": "8.2 A GLM prediction",
    "text": "8.2 A GLM prediction\nLet’s start with the generalized linear model: we’re going to predict whether or not a person will be granted a mortgage. To do this, we’ll use the loanapp database available in the package(wooldridge), which we’ll filter on certain variables to make our work clearer:\n\nlibrary(wooldridge)\nlibrary(tidyverse)\nlibrary(stargazer)\ndf &lt;- as.data.frame(loanapp)\ndf &lt;- select(df,approve, hrat, obrat, dep, sch, white, hispan, unem, male, married, unver)\nhead(df)\n\n  approve  hrat obrat dep sch white hispan unem male married unver\n1       1 17.63  34.5   0   1     1      0  3.2   NA       0     0\n2       0 22.54  34.1   1   1     1      0  3.2    1       1     0\n3       1 19.00  26.0   0   1     1      0  3.9    1       0     0\n4       1 24.00  37.0   0   1     1      0  3.1    1       1     0\n5       1 25.10  32.1   0   0     1      0  4.3    1       1     0\n6       1 21.00  33.0   0   0     1      0  3.2    1       0     0\n\n\nWhere:\n\napprove: 1 if mortgage is approved, 0 otherwise\nhrat: housing expenditures, percent total income\nobrat: other obligations, percent total income\ndep: number of dependents\nsch: 1 if &gt; 12 years schooling\nwhite: 1 if white, 0 otherwise\nhispan: 1 if hispan, 0 otherwise\nunem: unemployment rate by industry\nmale: 1 if male, 0 otherwise\nmarried: 1 if married, 0 otherwise\nunever: unverifiable info in the file\n\nNow we can get down to business… We’re going to split our sample in two, one for training and one for testing, with the first 1,400 lines for training and the remainder for testing.\nThen we perform a probit regression (to calculate the probabilities that approve =1) using the glm function for Generalized Linear Model:\n\ndf.train &lt;- df[1:1400, ]\ndf.test &lt;- df[-c(1:1400), ]\n\nmodel &lt;- glm(approve ~ hrat + obrat + dep + sch + white + hispan + unem + male + married + unver, \n                    family=binomial(link='probit'), data=df.train)\nstargazer(model, type = \"text\", single.row = TRUE, header = FALSE)\n\n\n=============================================\n                      Dependent variable:    \n                  ---------------------------\n                            approve          \n---------------------------------------------\nhrat                    0.017** (0.008)      \nobrat                  -0.036*** (0.007)     \ndep                     -0.013 (0.046)       \nsch                      0.065 (0.112)       \nwhite                  0.755*** (0.131)      \nhispan                   0.262 (0.204)       \nunem                    -0.037* (0.020)      \nmale                    -0.114 (0.132)       \nmarried                 0.227** (0.112)      \nunver                  -1.678*** (0.185)     \nConstant               1.518*** (0.287)      \n---------------------------------------------\nObservations                 1,384           \nLog Likelihood             -431.198          \nAkaike Inf. Crit.           884.397          \n=============================================\nNote:             *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nOnce the coefficients of the regressors have been calculated by our model, we will predict the probability of obtaining a credit on the test sample. For simplicity’s sake, we’ll assume that credit is granted if the probability of obtaining it is greater than 0.5.\nFinally, we create a table showing the number of credits granted or not, based on what the model has predicted:\n\ndf.predict &lt;- predict(model, newdata=df.test, type='response')\nhead(df.predict)\n\n     1401      1402      1403      1404      1405      1406 \n0.9596548 0.9474160 0.9613475 0.9222669 0.9347621 0.9203146 \n\n# Percentage of good predictions\ndf.predict &lt;- ifelse(df.predict &gt; 0.5, 1, 0)\nPredictionAccuracy &lt;- mean(df.predict == df.test$approve)\n\n\n\n# Transform into factors\ndf.predict &lt;- factor(df.predict, levels = c(0,1), labels = c(\"predicted reject\", \"predicted accept\"))\ndf.test$Decision &lt;- factor(df.test$approve, levels = c(0,1), labels = c(\"rejected\", \"accepted\"))\n\n# Create the table\ntable(df.predict,df.test$Decision)\n\n                  \ndf.predict         rejected accepted\n  predicted reject       17        7\n  predicted accept       54      509\n\nprop.table(table(df.predict,df.test$Decision),2)\n\n                  \ndf.predict           rejected   accepted\n  predicted reject 0.23943662 0.01356589\n  predicted accept 0.76056338 0.98643411\n\n\nOur model was wrong in only 11% of cases. That’s not so bad!"
  },
  {
    "objectID": "ML.html#random-forest",
    "href": "ML.html#random-forest",
    "title": "8  Machine Learning",
    "section": "8.3 Random Forest",
    "text": "8.3 Random Forest\n\nlibrary(randomForest)\n  df$Decision &lt;- factor(df$approve, levels = c(0,1), labels = c(\"rejected\", \"approved\"))\nRF &lt;- randomForest(Decision ~ hrat + obrat + dep + sch + white + hispan + unem + male + married + unver, ntree=5000, data = df, na.action = na.roughfix)\nprint(RF)\n\n\nCall:\n randomForest(formula = Decision ~ hrat + obrat + dep + sch +      white + hispan + unem + male + married + unver, data = df,      ntree = 5000, na.action = na.roughfix) \n               Type of random forest: classification\n                     Number of trees: 5000\nNo. of variables tried at each split: 3\n\n        OOB estimate of  error rate: 11.87%\nConfusion matrix:\n         rejected approved class.error\nrejected       48      196  0.80327869\napproved       40     1705  0.02292264\n\nvarImpPlot(RF)\n\n\n\n\n\npredictors &lt;- data.frame(hrat=20, obrat=25, dep=0, sch=0, white=0, \n                         hispan=1, unem=3.2, male=0, married=1, unver=1)\npredict(model, predictors, type=\"response\")\n\n        1 \n0.3580895 \n\npredict(RF, predictors, type=\"response\")\n\n       1 \nrejected \nLevels: rejected approved"
  },
  {
    "objectID": "ML.html#learning-by-doing",
    "href": "ML.html#learning-by-doing",
    "title": "8  Machine Learning",
    "section": "8.4 Learning by doing",
    "text": "8.4 Learning by doing\nAlong with Titanic, the Iris database is a must-have in any machine learning course! It’s all about grouping iris flowers by type, letting the computer choose groups according to the characteristics of the petals and sepals. Run the following code line by line, and try to understand every step!\n\n\n\n\n\n\nK-means clustering\n\n\n\n\n\n\nlibrary(ggplot2)\nlibrary(cluster)\ndf &lt;- iris\nView(df)\nggplot(df, aes(Petal.Length, Petal.Width)) + geom_point(aes(col=Species), size=4)\nset.seed(101)\nirisCluster &lt;- kmeans(df[,1:4], center=3, nstart=20)\nirisCluster\ntable(irisCluster$cluster, df$Species)\nclusplot(iris, irisCluster$cluster, color=T, shade=T, labels=0, lines=0)"
  },
  {
    "objectID": "ML.html#exercices",
    "href": "ML.html#exercices",
    "title": "8  Machine Learning",
    "section": "8.5 Exercices",
    "text": "8.5 Exercices\n\nWhich Technic allows you to reduce the number of dimensions in your data? \nWhich table summarizes the model’s good and bad decisions? Predict TableProp TableOOBConfusion Matrix\nWhich algorithm can solve both regression and classification tasks? NoneK-mean clusteringLogistic RegressionDecision Trees\nHow do we change missing values by the median? \nThere’s no point in learning how to code then, the machines will do everything for us! TRUEFALSE"
  },
  {
    "objectID": "DataViz.html#rmarkdown",
    "href": "DataViz.html#rmarkdown",
    "title": "9  DataViz",
    "section": "9.1 Rmarkdown",
    "text": "9.1 Rmarkdown\nLet’s start by creating a new .rmd file with the following command: File -&gt; New File -&gt; R Markdown -&gt; Document and press Create. You should be here:\n\n\n\n\nPress the Knit button and you can generate a pdf or HTML document! And in this document you’ll be able to run R code with the help of chunks, the place where you write your code in R or any other language.\nCode chunks are integral components that allow the seamless integration of executable R code within a document. These chunks are delineated by triple backticks with {r} indicating R code. During the document rendering process, the R code within these chunks is executed, and the results are displayed in the final document. Various options, such as echo, eval, and results, provide fine-grained control over the behavior of code chunks. The echo option determines whether the code is displayed in the document, while eval specifies if the code should be run. The results option governs the display of code results, with default settings often producing markup.\nInline code, denoted by backticks (e.g., r code here), allows the seamless inclusion of R code within the document’s narrative. Additionally, code chunks support features like chunk labels for reference or organization, sourcing external R scripts for modularity, and caching outputs to enhance rendering speed. Graphics generated within code chunks are automatically embedded, and these chunks share the same session state, facilitating consistency. Error handling options, such as error and warning, provide mechanisms for managing unexpected outcomes. Furthermore, code chunks can incorporate interactive elements, including Shiny apps, adding a layer of dynamism to the document. Overall, code chunks in R Markdown enhance the document’s reproducibility, enabling a cohesive blend of narrative and executable code."
  },
  {
    "objectID": "DataViz.html#example-with-maps",
    "href": "DataViz.html#example-with-maps",
    "title": "9  DataViz",
    "section": "9.2 Example with Maps",
    "text": "9.2 Example with Maps\nIn this example, we’ll be using interactive data and maps. The aim is to solve a data science problem by presenting it interactively.\nHere are your instructions: your family is visiting you in Toulouse, and you want them to see 11 of the city’s best-known sights. The idea is to see each of them once and find the shortest path linking all 11. For simplicity’s sake, we’ll assume that the routes are as the crow flies.\nHere are the GPS coordinates of the sites:\n\n\n\n\n\nMonument\nlng\nlat\n\n\n\n\nCapitole\n43.60436\n1.443435\n\n\nSaint Sernin\n43.60823\n1.441099\n\n\nSaint Etienne\n43.59983\n1.449133\n\n\nJardin des plantes\n43.59134\n1.452842\n\n\nPalais de Justice\n43.59420\n1.443998\n\n\nPont Neuf\n43.59960\n1.440368\n\n\nChez Tonton\n43.60379\n1.435273\n\n\nIle du Ramier\n43.58557\n1.435692\n\n\nAbattoirs\n43.60072\n1.428817\n\n\nSaint Aubin\n43.60361\n1.454207\n\n\nPrairie des filtres\n43.59557\n1.436918\n\n\n\n\n\n\n Download data as xlsx\n\n\n\n\n\n\n\n\n\nThis problem is a classic in data science, especially in supply chain management. To solve it, we’ll use the TSP package, i.e the Travel Salesman Problem. This involves creating a distance matrix from GPS coordinates and calculating all possible path combinations on all sites, then selecting the shortest of them all. Here’s the code that solves the problem:\n\n# Distance matrix\ndist_mat &lt;- \n  dist(\n    Toulouse_Monument %&gt;% select(lng, lat),\n    method = 'euclidean'\n  )\n# Initialize the TSP object\ntsp_prob &lt;- TSP(dist_mat)\n# We add a dummy to the TSP, in this way we remove\n# the constraint of having a path that ends at the\n# starting point\ntsp_prob &lt;- insert_dummy(tsp_prob, label = 'dummy')\n# TSP solver\n\nTest1 &lt;- as.data.frame(dist_mat)\n\ntour &lt;-\n  solve_TSP(\n    tsp_prob,\n    method = 'two_opt',\n    control = list(rep = 16)\n  )\n# Optimal path\npath &lt;- names(cut_tour(tour, 'dummy'))\n\nTest &lt;- Toulouse_Monument %&gt;%\n  mutate(id_order = order(as.integer(path)))\n\nTest &lt;- Test %&gt;% arrange(desc(id_order))\n# Plot a map with the data and overlay the optimal path\nleaflet(data = Test) %&gt;% addTiles() %&gt;%\n  addMarkers(~lat, ~lng, popup = ~Monument, label = ~paste(Monument, \" \", id_order)) %&gt;% \n  addPolylines(~lat, ~lng)\n\n\n\n\nTour1 &lt;- as.data.frame(Test)\nknitr::kable(head(Test,11), col.names = gsub(\"[.]\", \" \", names(Test)))          \n\n\n\n\nMonument\nlng\nlat\nid_order\n\n\n\n\nSaint Aubin\n43.60361\n1.454207\n11\n\n\nSaint Etienne\n43.59983\n1.449133\n10\n\n\nJardin des plantes\n43.59134\n1.452842\n9\n\n\nPalais de Justice\n43.59420\n1.443998\n8\n\n\nPont Neuf\n43.59960\n1.440368\n7\n\n\nCapitole\n43.60436\n1.443435\n6\n\n\nSaint Sernin\n43.60823\n1.441099\n5\n\n\nChez Tonton\n43.60379\n1.435273\n4\n\n\nAbattoirs\n43.60072\n1.428817\n3\n\n\nPrairie des filtres\n43.59557\n1.436918\n2\n\n\nIle du Ramier\n43.58557\n1.435692\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis book was written entirely in Quarto, a recent enhancement to Rmarkdown. In the following section you’ll be asked to use a Quarto file, but it works just fine in Rmarkdown. You can also install the Quarto package!"
  },
  {
    "objectID": "DataViz.html#learning-by-doing",
    "href": "DataViz.html#learning-by-doing",
    "title": "9  DataViz",
    "section": "9.3 Learning by doing",
    "text": "9.3 Learning by doing\nThis time you’ll download the Quarto script used to generate this page. The aim is for you to be able to reproduce this entire document with Leaflet’s interactive maps and elegantly presented data tables!\n\n\n\n\n\n\nQuarto Script\n\n\n\n\n\n\n\nDownload DataViz.qmd"
  },
  {
    "objectID": "DataViz.html#exercices",
    "href": "DataViz.html#exercices",
    "title": "9  DataViz",
    "section": "9.4 Exercices",
    "text": "9.4 Exercices\n\nWhich option allows you not to show the code in a chunk? \nWhich button generates the markdown document? RunVisualOutlineKnit\nWhat is the Quarto file extension? .quarto.rmd.rqua.qmd\nWhich option allows you not to run the code in a chunk? \nWow, we can even write a stylish report with Rstudio! TRUEFALSE"
  },
  {
    "objectID": "Exam.html#exercice-1-5-points",
    "href": "Exam.html#exercice-1-5-points",
    "title": "10  Exam",
    "section": "10.1 Exercice 1 (5 points)",
    "text": "10.1 Exercice 1 (5 points)\n\nCreate a 6-sided dice by creating a data frame containing the numbers 1 through 6.\nMake 500 random draws of this dice and store the results in a dataframe called df. Draw the results in an histogram. Hint: use sample instead of runif!\nCreate a function that takes \\(n\\) as input and returns \\(n\\) random draws of the dice.\nCreate a function \\(f(n)\\) that takes \\(n\\) as input and returns the difference between your sample mean and your dice mean.\nCompute \\(f(100)\\), \\(f(1000)\\) and \\(f(100000)\\). What can you conclude?\n\n\n\n\n\n\n\nSolution Exercice 1\n\n\n\n\n\n\n# 1.\ndice &lt;- c(1,2,3,4,5,6)\n\n\n# 2.\ndraw &lt;- sample(dice,500,replace=T)\ndf &lt;- as.data.frame(dice)\nhist(draw, col='steelblue', main='Histogram of Dice')\n\n\n\n\n\n# 3.\nSample_dice &lt;- function(n){\n  Out &lt;- sample(dice,n,replace=T)\n  return(Out)\n}\n\n\n# 4.\nf &lt;- function(n){\n  X &lt;- 3.5 - mean(Sample_dice(n))\n  return(X)\n}\n\n\n# 1.\nf(100)\n\n[1] 0.15\n\nf(1000)\n\n[1] -0.011\n\nf(100000)\n\n[1] -0.00879\n\n# It converges to 0, due to the law of large number."
  },
  {
    "objectID": "Exam.html#exercice-2-10-points",
    "href": "Exam.html#exercice-2-10-points",
    "title": "10  Exam",
    "section": "10.2 Exercice 2 (10 points)",
    "text": "10.2 Exercice 2 (10 points)\n\n\n\n Download df1 as csv\n\n\n\n\n Download df2 as csv\n\n\n\nDownload the file “data.csv”. You are a Data Scientist who wants to hire interns. In a test, you ask 12 candidates to do 6 tasks, each on R and Python and you will collect the time needed to do it.\nThe dataset is organized as following:\n\nID: The intern’s ID number.\nTool: The software used, either R or Python.\nEvents: the 6 different tasks to do on both tools.\nTime: time needed to complete the task.\n\n\nRead the dataset into R, and assign the variables as following:\n\n\nID is a factor\nTool is a factor\nTime is numeric\nNAs are removed\n\n\n\n\n\n\n\nSolution Question 1\n\n\n\n\n\n\ndf1 &lt;- read.csv(\"data/df1.csv\", sep=\";\")\n\ndf1$ID &lt;- as.numeric(df1$ID)\ndf1$Tool &lt;- as.factor(df1$Tool)\ndf1$Time &lt;- as.numeric(df1$Time)\n\ndf1 &lt;- filter(df1,!is.na(df1$Time))\nhead(df1)\n\n  ID Tool Events Time\n1  1    R      1  130\n2  1    R      2  158\n3  1    R      3  125\n4  1    R      4  127\n5  1    R      5  137\n6  1    R      6  130\n\n\n\n\n\n\nCreate the factor Gender and add it to the dataset.\n\n\nID 1-6 are males\nID 7-12 are females\n\n\n\n\n\n\n\nSolution Question 2\n\n\n\n\n\n\ndf1$Gender &lt;- ifelse(df1$ID &lt;7 ,\"male\",\"female\")\nhead(df1)\n\n  ID Tool Events Time Gender\n1  1    R      1  130   male\n2  1    R      2  158   male\n3  1    R      3  125   male\n4  1    R      4  127   male\n5  1    R      5  137   male\n6  1    R      6  130   male\n\n\n\n\n\n\nCreate the factor Age and add it to the dataset. This factor has three levels: young, mid, old.\n\n\nID 1, 3, 4, 7 are young\nID 2, 5, 6, 8 are mid\nID 9 through 12 are old\n\n\n\n\n\n\n\nSolution Question 3\n\n\n\n\n\n\ndf1$Age &lt;- as.factor(df1$ID)\ndf1$Age &lt;- gsub(\"1|3|4|7\", \"young\", df1$Age)\ndf1$Age &lt;- gsub(\"2|5|6|8\", \"mid\", df1$Age)\ndf1$Age &lt;- gsub(\"9|10|11|12\", \"old\", df1$Age)\n\n\n\nhead(df1)\n\n  ID Tool Events Time Gender   Age\n1  1    R      1  130   male young\n2  1    R      2  158   male young\n3  1    R      3  125   male young\n4  1    R      4  127   male young\n5  1    R      5  137   male young\n6  1    R      6  130   male young\n\n\n\n\n\nBefore the test, it was asked to the candidate to give their final Exam grades on R and Python, as well as the wage they want for one hour working. All this data is on the file “df2.csv”.\n\nAdd the variable Wage to your first dataset. Carreful: the number of rows must not change!\n\n\n\n\n\n\n\nSolution Question 4\n\n\n\n\n\n\nlibrary(tidyverse)\ndf2 &lt;- read.csv(\"data/df2.csv\", sep=\";\")\nhead(df2)\n\n  ID   Tool Exam Wage\n1  1      R   19   10\n2  1 Python   15   10\n3  2 Python   14    9\n4  2      R   15    9\n5  3 Python   10    9\n6  3      R   16    9\n\ndf3 &lt;- df2 %&gt;% select(ID,Wage) %&gt;% unique()\ndf1 &lt;- left_join(df1,df3,by=\"ID\")\nhead(df1)\n\n  ID Tool Events Time Gender   Age Wage\n1  1    R      1  130   male young   10\n2  1    R      2  158   male young   10\n3  1    R      3  125   male young   10\n4  1    R      4  127   male young   10\n5  1    R      5  137   male young   10\n6  1    R      6  130   male young   10\n\n\n\n\n\n\nCreate a table that summarize the results: display the mean of Time for each ID and Tool.\n\n\n\n\n\n\n\nSolution Question 5\n\n\n\n\n\n\nlibrary(tidyverse)\nTable1 &lt;- df1 %&gt;% group_by(ID,Tool) %&gt;% summarise(mean = mean(Time))\n\n`summarise()` has grouped output by 'ID'. You can override using the `.groups`\nargument.\n\nhead(Table1)\n\n# A tibble: 6 × 3\n# Groups:   ID [3]\n     ID Tool    mean\n  &lt;dbl&gt; &lt;fct&gt;  &lt;dbl&gt;\n1     1 Python  174.\n2     1 R       134.\n3     2 Python  124.\n4     2 R       113 \n5     3 Python  196.\n6     3 R       165.\n\n\n\n\n\n\nRank the table from the better candidate to the last one (i.e the shortest time) and keep only 3 candidates, whatever the tool used. Add a column that compute the total wage needed to realize the task for each candidate and select the cheapest! Who will be hired?\n\n\n\n\n\n\n\nSolution Question 6\n\n\n\n\n\n\nlibrary(tidyverse)\nTable2 &lt;- Table1 %&gt;% top_n(3, mean) %&gt;% arrange(mean)\nTable2 &lt;- Table2[1:4,]\nTable2 &lt;- left_join(Table2,df3,by=\"ID\")\nTable2$Wage_needed &lt;- Table2$mean * Table2$Wage\nTable2 &lt;- Table2 %&gt;% arrange(Wage_needed)\nhead(Table2)\n\n# A tibble: 4 × 5\n# Groups:   ID [3]\n     ID Tool    mean  Wage Wage_needed\n  &lt;dbl&gt; &lt;fct&gt;  &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt;\n1    10 Python  105      9        945 \n2    11 R       110.    10       1097.\n3     7 R       101.    11       1109.\n4     7 Python  102.    11       1126.\n\n# Candidate 10 is hired!\n\n\n\n\n\nYou will now only work on R (i.e forget Python). Create a new table with those variables: ID, Results (the mean of Time for the 6 tasks), Exam (R exam results), Gender, Age and Wage.\n\n\n\n\n\n\n\nSolution Question 7\n\n\n\n\n\n\nlibrary(tidyverse)\nTable3 &lt;-  Table1 %&gt;% filter(Tool==\"R\")\nTable4 &lt;-  df2 %&gt;% filter(Tool==\"R\")\ncolnames(Table3)[3] &lt;- \"Results\"\n#Table4 &lt;- df2 %&gt;% filter(Tool==\"R\")\n#Table4 &lt;- Table4[,-c(2:2)]\n#Table3 &lt;- Table3 %&gt;% group_by(ID) %&gt;% summarise(mean = mean(Time))\nhead(Table3)\n\n# A tibble: 6 × 3\n# Groups:   ID [6]\n     ID Tool  Results\n  &lt;dbl&gt; &lt;fct&gt;   &lt;dbl&gt;\n1     1 R        134.\n2     2 R        113 \n3     3 R        165.\n4     4 R        130.\n5     5 R        130.\n6     6 R        176.\n\ndf1 &lt;- left_join(df1,Table3,by=\"ID\")\ndf1 &lt;- left_join(df1,Table4,by=\"ID\")\ndf1 &lt;- df1 %&gt;% select(ID,Results,Exam,Gender,Age,Wage.y)\ncolnames(df1)[6] &lt;- \"Wage\"\ndf1 &lt;- df1 %&gt;% unique()\nhead(df1)\n\n   ID  Results Exam Gender   Age Wage\n1   1 134.5000   19   male young   10\n13  2 113.0000   15   male   mid    9\n24  3 165.2500   16   male young    9\n34  4 129.6667   18   male young   12\n46  5 130.5000   15   male   mid   10\n55  6 175.6667    9   male   mid    8\n\nhead(Table4)\n\n  ID Tool Exam Wage\n1  1    R   19   10\n2  2    R   15    9\n3  3    R   16    9\n4  4    R   18   12\n5  5    R   15   10\n6  6    R    9    8\n\n# Candidate 10 is hired!\n\n\n\n\n\nRun the following linear regression: \\(Wage = Results + Exam + Age + Gender+ \\epsilon\\). Interpret the results and export it in HTML, Text and Latex. Would you say that the candidates are quite honest in their salary expectations?\n\n\n\n\n\n\n\nSolution Question 8\n\n\n\n\n\n\nlibrary(stargazer)\n\n\nPlease cite as: \n\n\n Hlavac, Marek (2022). stargazer: Well-Formatted Regression and Summary Statistics Tables.\n\n\n R package version 5.2.3. https://CRAN.R-project.org/package=stargazer \n\nModel &lt;- lm(Wage ~ Results + Exam +  Gender, data = df1)\nstargazer(Model,type = \"text\")\n\n\n===============================================\n                        Dependent variable:    \n                    ---------------------------\n                               Wage            \n-----------------------------------------------\nResults                        0.006           \n                              (0.010)          \n                                               \nExam                          0.333**          \n                              (0.117)          \n                                               \nGendermale                    -0.359           \n                              (0.708)          \n                                               \nConstant                       4.007           \n                              (2.729)          \n                                               \n-----------------------------------------------\nObservations                    12             \nR2                             0.522           \nAdjusted R2                    0.343           \nResidual Std. Error       1.220 (df = 8)       \nF Statistic              2.910 (df = 3; 8)     \n===============================================\nNote:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01"
  },
  {
    "objectID": "Exam.html#exercice-3-5-points",
    "href": "Exam.html#exercice-3-5-points",
    "title": "10  Exam",
    "section": "10.3 Exercice 3 (5 points)",
    "text": "10.3 Exercice 3 (5 points)\n\nFor each of the 4 groups of lines of code below, explain in your own words the purpose of the code.\nIf you try to run the code an error will appear. Can you correct it, run the code and give the value of the fifth row?\n\n\n# 1.\nset.seed(123)\n\n# 2.\nID &lt;- c()\ndf1 &lt;- c()\ndf2 &lt;- c()\ndf3 &lt;- c()\n\n# 3.\nID &lt;- seq(1:100)\nID &lt;- as.data.frame(ID)\ndf1 &lt;- runif(100,0,1)\ndf1 &lt;- as.data.frame(df1)\ndf2 &lt;- rnorm(n = 100, mean = 2, sd = 5)\ndf2 &lt;- as.data.frame(df2)\ndf3 &lt;- rpois(101,2)\ndf3 &lt;- as.data.frame(df3)\ndf3[-101,]\ndf3 &lt;- as.data.frame(df3)\n\n# 4.\ndf &lt;- cbind(ID,df1,df2,df3)\ndf &lt;- gather(df,\"DF\",\"Score\",2:4)\n\n\n\n\n\n\n\nSolution Exercice 3\n\n\n\n\n\n1.1 set.seed(123) generates a sequence of pseudo random numbers such that the outcomes is the same for every user.\n1.2 We create 4 empty vectors.\n1.3 We create 4 dataframes made of different laws of probabilities: a sequence from 1 to 100, a uniform law with runif, a normal law with rnorm and a Poisson law with rpois. df3 has 101 observations, so we try to erase the number 101 with df3[-101,]. But the object remains unchanged, so we miss df3 &lt;- df3[-101,]. This is the error.\n1.4 We bind the columns into a single dataframe df and we make the data tidy with df &lt;- gather(df,\"DF\",\"Score\",2:4)\n\n# 1.\nset.seed(123)\n\n# 2.\nID &lt;- c()\ndf1 &lt;- c()\ndf2 &lt;- c()\ndf3 &lt;- c()\n\n# 3.\nID &lt;- seq(1:100)\nID &lt;- as.data.frame(ID)\ndf1 &lt;- runif(100,0,1)\ndf1 &lt;- as.data.frame(df1)\ndf2 &lt;- rnorm(n = 100, mean = 2, sd = 5)\ndf2 &lt;- as.data.frame(df2)\ndf3 &lt;- rpois(101,2)\ndf3 &lt;- as.data.frame(df3)\ndf3 &lt;- df3[-101,]\ndf3 &lt;- as.data.frame(df3)\n\n# 4.\ndf &lt;- cbind(ID,df1,df2,df3)\ndf &lt;- gather(df,\"DF\",\"Score\",2:4)\nhead(df)\n\n  ID  DF     Score\n1  1 df1 0.2875775\n2  2 df1 0.7883051\n3  3 df1 0.4089769\n4  4 df1 0.8830174\n5  5 df1 0.9404673\n6  6 df1 0.0455565\n\n\n\nThe value of the fifth row is 0.9404673"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Wickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023.\nR for Data Science. \" O’Reilly Media, Inc.\".\n\n\nWooldridge, Jeffrey M. 2015. Introductory Econometrics: A Modern\nApproach. Cengage learning."
  }
]